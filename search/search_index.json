{"config":{"indexing":"full","lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"ACKNOWLEDGEMENTS Special thanks to Craig Brandt, Robin Bobbitt, other Red Hat colleagues for use of the Technical Preview of IBM watsonx Code Assistant for Red Hat Ansible Lightspeed . Generally speaking, Generative AI is the talk of the town in 2023 \u2014 and likely will remain so for years to come. What began to simmer in the early 2020s as excitement within academic and technology communities around transformers has today exploded into a firestorm of interest and investment across nearly every industry, institution, and government. For the first time at scale, everyday consumers have access to artificial intelligence on their phones and through their web browsers. Likewise, enterprise and business leaders no longer view AI as a topic of interest, but as a critical imperative to success in the future economy. Foundation Models \u2014 a term coined by Stanford University \u2014are built using a specific kind of neural network architecture, called a transformer . The transformer helps the Foundation Model understand unlabeled data and turn an input into an output. The most consequential manifestation of this technology so far is what we know today as \" Generative AI .\" So what is Generative AI ? The vast topic refers to a subset of AI techniques and methodologies that are designed to generate new content \u2014 in other words, AI applied towards the creation of novel content in the form of images, text, voice, or even code. This sharply differs from the goals of more \"traditional\" AI models of the past, which have primarily been focused on the analysis and classification (labeling) of information. Historically, these early pioneering techniques of AI models have progressed from simple probabilistic models into increasingly sophisticated systems, building upon concepts like neural networks and deep learning techniques. Today, technologies like Generative AI showcase not only the ability to perform analysis, but also tremendous capacity for creation. Even the creation of application code and automation tasks. The advent of Foundation Models and Generative AI, given their remarkable performance and extensibility to a wide range of tasks, has brought about an inflection point in AI. Recognizing the significance of the moment, IBM enterprise clients are actively evaluating and seeking to incorporate Foundation Models into critical business workflows and applications \u2014 anything and everything which might involve generation, summarization, classification, and so many other use cases. The notion of automating the generation of Ansible Playbook code with AI stems from the challenges and bottlenecks often faced by developers tasked with traditional, manual creation of Playbooks. Developers and programmers must craft precise, error-free Playbooks which are potentially automating jobs across vast collections of assets or hardware. One of the benefits of automation is being able to perform such tasks at-scale; conversely, this also poses one of the greatest risks of automation \u2014 that when things fail, they can fail rapidly and across vast swathes of IT estate. It should come as no surprise, then, that authoring Playbooks often demands technical expertise and a deep understanding of the targeted systems and services which Ansible is to automate. Generative AI, especially models like GPT, have recently demonstrated proficiency in creating syntactically correct and contextually relevant application code in a variety of programming languages. If trained on a large dataset of Ansible Playbooks, Generative AI models can be fine-tuned to understand the nuances of Playbook syntax and structure. An enterprise organization with dozens or hundreds of Playbooks within their IT estate today would have a rich corpus of training data on-hand that could be used to fine-tune AI models that are tailored to the automation needs and programming style or standards of that particular company. As we will see, productized versions of Generative AI models can provide a natural language prompt to users which in turn is understood and translated by the AI models into the necessary Ansible Task code. For example, a user might describe a desired system state in plain language (\"I want a Playbook to install and start the Apache web server\") and the model will generate the appropriate Ansible Tasks for a Playbook. All of this achieved without physically writing code or requiring much programming expertise. Not only does this speed up the automation process by cutting the time needed to author Playbooks, but it also democratizes access to automation in general. Even those within a company with limited Ansible or programming expertise will be able to produce effective Playbooks. There are plenty of caveats of course, and thorough validation and testing of AI-generated code will be needed before being put into production. However, the productivity gains and broadening of skillsets within an organization can be tremendous. And as a whole, Generative AI brings the original goals of Red Hat Ansible Automation Platform (the democratization of automation for everything) that much closer to a reality. The material covered in this Level 3 coursework will prepare IBM and business partner technical sellers with the skills necessary to demonstrate Ansible Playbook task creation using the generative AI capabilities of IBM watsonx Code Assistant for Red Hat Ansible Lightspeed . A client demo-ready Technical Preview is available free of charge through the open source community which you will build upon and extend for this hands-on learning via Visual Studio Code ( VS Code ) on your local machine. This service uses, among other data, Playbooks and Collections that are available through the Red Hat community website, Ansible Galaxy . The documentation within this Level 3 lab will cover how to set up VS Code on your local machine (macOS or Windows) with an extension for IBM watsonx Code Assistant for Red Hat Ansible Lightspeed . You will then leverage the generative AI code recommendations provided by the extension for creating a variety of Ansible Playbooks for automating cloud-based and infrastructure-based automation tasks, such as: Installing and configuring Cockpit for Ansible Preparing an AWS and Azure cloud environment Provisioning an AWS EC2 instance Provisioning an Azure virtual machine (VM) Running a Podman 'pgadmin' container Deploying and starting a PostgreSQL database server These short demonstrations will go beyond simply giving you hands-on experience with Ansible Lightspeed's generative AI capabilities for Ansible Playbook task creation. In-depth explanations accomanying the Playbooks will also explain: The integrations that IBM watsonx Code Assistant for Red Hat Ansible Lightspeed provides How Ansible Lightspeed uses natural language prompts, as well as the Ansible Playbook contents, to generate contextually-aware Task code recommendations Pre-processing and post-processing capabilities that refine the generative AI suggestions into syntactically correct code (adherent to best practices) How Ansible Lightspeed provides \"explainability\" and source content matching attribution for all AI-generated content To conclude the Level 3 Technical Sales education on IBM watsonx Code Assistant for Red Hat Ansible Lightspeed , you will be provided with a complete set of instructions for deploying a LIVE Amazon Web Services (AWS) environment with Ansible automation, consisting of a WordPress web application running atop an Amazon EC2 VPC . The deployment of the environments will be conducted entirely using Red Hat Ansible automation, executed on your local machine, and deployed to AWS cloud. The generation of Ansible Tasks and code required to automate these deployments will be created using the Generative AI capabilities of the Ansible Lightspeed extension for VS Code. Ahead, we will outline the evaluation criteria for IBM technical sellers and business partners. Afterwards, you will setup your local environment with the necessary pre-requisites for getting started with the hands-on material.","title":"Introduction"},{"location":"#_1","text":"","title":""},{"location":"#generally-speaking-generative-ai-is-the-talk-of-the-town-in-2023-and-likely-will-remain-so-for-years-to-come","text":"What began to simmer in the early 2020s as excitement within academic and technology communities around transformers has today exploded into a firestorm of interest and investment across nearly every industry, institution, and government. For the first time at scale, everyday consumers have access to artificial intelligence on their phones and through their web browsers. Likewise, enterprise and business leaders no longer view AI as a topic of interest, but as a critical imperative to success in the future economy. Foundation Models \u2014 a term coined by Stanford University \u2014are built using a specific kind of neural network architecture, called a transformer . The transformer helps the Foundation Model understand unlabeled data and turn an input into an output. The most consequential manifestation of this technology so far is what we know today as \" Generative AI .\" So what is Generative AI ? The vast topic refers to a subset of AI techniques and methodologies that are designed to generate new content \u2014 in other words, AI applied towards the creation of novel content in the form of images, text, voice, or even code. This sharply differs from the goals of more \"traditional\" AI models of the past, which have primarily been focused on the analysis and classification (labeling) of information. Historically, these early pioneering techniques of AI models have progressed from simple probabilistic models into increasingly sophisticated systems, building upon concepts like neural networks and deep learning techniques. Today, technologies like Generative AI showcase not only the ability to perform analysis, but also tremendous capacity for creation. Even the creation of application code and automation tasks. The advent of Foundation Models and Generative AI, given their remarkable performance and extensibility to a wide range of tasks, has brought about an inflection point in AI. Recognizing the significance of the moment, IBM enterprise clients are actively evaluating and seeking to incorporate Foundation Models into critical business workflows and applications \u2014 anything and everything which might involve generation, summarization, classification, and so many other use cases.","title":"Generally speaking, Generative AI is the talk of the town in 2023 \u2014 and likely will remain so for years to come."},{"location":"#_2","text":"","title":""},{"location":"#the-notion-of-automating-the-generation-of-ansible-playbook-code-with-ai-stems-from-the-challenges-and-bottlenecks-often-faced-by-developers-tasked-with-traditional-manual-creation-of-playbooks","text":"Developers and programmers must craft precise, error-free Playbooks which are potentially automating jobs across vast collections of assets or hardware. One of the benefits of automation is being able to perform such tasks at-scale; conversely, this also poses one of the greatest risks of automation \u2014 that when things fail, they can fail rapidly and across vast swathes of IT estate. It should come as no surprise, then, that authoring Playbooks often demands technical expertise and a deep understanding of the targeted systems and services which Ansible is to automate. Generative AI, especially models like GPT, have recently demonstrated proficiency in creating syntactically correct and contextually relevant application code in a variety of programming languages. If trained on a large dataset of Ansible Playbooks, Generative AI models can be fine-tuned to understand the nuances of Playbook syntax and structure. An enterprise organization with dozens or hundreds of Playbooks within their IT estate today would have a rich corpus of training data on-hand that could be used to fine-tune AI models that are tailored to the automation needs and programming style or standards of that particular company. As we will see, productized versions of Generative AI models can provide a natural language prompt to users which in turn is understood and translated by the AI models into the necessary Ansible Task code. For example, a user might describe a desired system state in plain language (\"I want a Playbook to install and start the Apache web server\") and the model will generate the appropriate Ansible Tasks for a Playbook. All of this achieved without physically writing code or requiring much programming expertise. Not only does this speed up the automation process by cutting the time needed to author Playbooks, but it also democratizes access to automation in general. Even those within a company with limited Ansible or programming expertise will be able to produce effective Playbooks. There are plenty of caveats of course, and thorough validation and testing of AI-generated code will be needed before being put into production. However, the productivity gains and broadening of skillsets within an organization can be tremendous. And as a whole, Generative AI brings the original goals of Red Hat Ansible Automation Platform (the democratization of automation for everything) that much closer to a reality.","title":"The notion of automating the generation of Ansible Playbook code with AI stems from the challenges and bottlenecks often faced by developers tasked with traditional, manual creation of Playbooks."},{"location":"#_3","text":"","title":""},{"location":"#the-material-covered-in-this-level-3-coursework-will-prepare-ibm-and-business-partner-technical-sellers-with-the-skills-necessary-to-demonstrate-ansible-playbook-task-creation-using-the-generative-ai-capabilities-of-ibm-watsonx-code-assistant-for-red-hat-ansible-lightspeed","text":"A client demo-ready Technical Preview is available free of charge through the open source community which you will build upon and extend for this hands-on learning via Visual Studio Code ( VS Code ) on your local machine. This service uses, among other data, Playbooks and Collections that are available through the Red Hat community website, Ansible Galaxy . The documentation within this Level 3 lab will cover how to set up VS Code on your local machine (macOS or Windows) with an extension for IBM watsonx Code Assistant for Red Hat Ansible Lightspeed . You will then leverage the generative AI code recommendations provided by the extension for creating a variety of Ansible Playbooks for automating cloud-based and infrastructure-based automation tasks, such as: Installing and configuring Cockpit for Ansible Preparing an AWS and Azure cloud environment Provisioning an AWS EC2 instance Provisioning an Azure virtual machine (VM) Running a Podman 'pgadmin' container Deploying and starting a PostgreSQL database server These short demonstrations will go beyond simply giving you hands-on experience with Ansible Lightspeed's generative AI capabilities for Ansible Playbook task creation. In-depth explanations accomanying the Playbooks will also explain: The integrations that IBM watsonx Code Assistant for Red Hat Ansible Lightspeed provides How Ansible Lightspeed uses natural language prompts, as well as the Ansible Playbook contents, to generate contextually-aware Task code recommendations Pre-processing and post-processing capabilities that refine the generative AI suggestions into syntactically correct code (adherent to best practices) How Ansible Lightspeed provides \"explainability\" and source content matching attribution for all AI-generated content To conclude the Level 3 Technical Sales education on IBM watsonx Code Assistant for Red Hat Ansible Lightspeed , you will be provided with a complete set of instructions for deploying a LIVE Amazon Web Services (AWS) environment with Ansible automation, consisting of a WordPress web application running atop an Amazon EC2 VPC . The deployment of the environments will be conducted entirely using Red Hat Ansible automation, executed on your local machine, and deployed to AWS cloud. The generation of Ansible Tasks and code required to automate these deployments will be created using the Generative AI capabilities of the Ansible Lightspeed extension for VS Code. Ahead, we will outline the evaluation criteria for IBM technical sellers and business partners. Afterwards, you will setup your local environment with the necessary pre-requisites for getting started with the hands-on material.","title":"The material covered in this Level 3 coursework will prepare IBM and business partner technical sellers with the skills necessary to demonstrate Ansible Playbook task creation using the generative AI capabilities of IBM watsonx Code Assistant for Red Hat Ansible Lightspeed."},{"location":"Lab/1-Evaluation/","text":"Evaluation Criteria for IBM Technical Sellers and Business Partners To receive Level 3 accreditation, IBMers and Business Partners must demonstrate mastery of the skills learned throughout the various modules of these hands-on labs and coursework. Level 3 accreditation requirements\u2014 and the way participants will be evaluated before receiving accreditation \u2014differs depending on job role. IBM TECHNICAL SELLERS IBM Sales and Tech Sales must develop and record a Stand & Deliver presentation. This video is intended to simulate your delivery of a \u201clive\u201d demo in front of a client \u2014 on camera. IBMers will have flexibility in defining a hypothetical client, the pain points that customer has, and the goals they aspire to. The recording will then cover the seller\u2019s hands-on demonstration and pitch to the client of the value of the IBM solution using the environments and techniques of this lab. BUSINESS PARTNERS Business Partners must pass an accreditation quiz after completing the hands-on portion of the course. The quiz consists of multiple choice questions, with four possible responses (and only one correct answer) for each question. The quiz questions will ask you about on-screen text or descriptions that come up as you work through the lab guide. IBMer Stand & Deliver Assessment IBMers \u2014 SUBMIT RECORDINGS HERE Submit your Stand & Deliver recording online using IBM YourLearning: < LINK GOES HERE > The evaluation criteria described below only applies to IBMers , who must record a Stand & Deliver presentation to receive accreditation for this Level 3 course. IBMers will be evaluated by First Line Manager (FLM). Instructions on how to submit a Stand & Deliver are included on this page. IBM Technical Sellers need to include all six of the following elements in their Stand & Deliver recording to receive Level 3 accreditation: Seller articulated client's pain point(s) and the value proposition of using IBM watsonx Code Assistant for Red Hat Ansible Lightspeed . Seller highlighted use cases for IBM watsonx Code Assistant for Red Hat Ansible Lightspeed . Seller demonstrated and discussed several of the key differentiated capabilities of IBM watsonx Code Assistant for Red Hat Ansible Lightspeed that deliver on the value proposition on point one. Seller highlighted benefits to the client (this is the why the client can\u2019t live without these benefits section). Seller highlighted benefits to the client's customers (what will the client be able to deliver to their customers that they could not without this product). Seller closed the demo with a call to action for the client that could include: a workshop, a deeper dive into the product meeting, Proof of Experience (PoX) engagements, and so on. Business Partner Quiz Assessment PARTNERS \u2014 COMPLETE ASSESSMENT HERE Complete your assessment online using IBM Training: < LINK GOES HERE > The accreditation quiz consists of multiple choice questions, with four possible responses (and only one correct answer) for each question.","title":"Evaluation"},{"location":"Lab/1-Evaluation/#evaluation-criteria-for-ibm-technical-sellers-and-business-partners","text":"To receive Level 3 accreditation, IBMers and Business Partners must demonstrate mastery of the skills learned throughout the various modules of these hands-on labs and coursework. Level 3 accreditation requirements\u2014 and the way participants will be evaluated before receiving accreditation \u2014differs depending on job role. IBM TECHNICAL SELLERS IBM Sales and Tech Sales must develop and record a Stand & Deliver presentation. This video is intended to simulate your delivery of a \u201clive\u201d demo in front of a client \u2014 on camera. IBMers will have flexibility in defining a hypothetical client, the pain points that customer has, and the goals they aspire to. The recording will then cover the seller\u2019s hands-on demonstration and pitch to the client of the value of the IBM solution using the environments and techniques of this lab. BUSINESS PARTNERS Business Partners must pass an accreditation quiz after completing the hands-on portion of the course. The quiz consists of multiple choice questions, with four possible responses (and only one correct answer) for each question. The quiz questions will ask you about on-screen text or descriptions that come up as you work through the lab guide.","title":"Evaluation Criteria for IBM Technical Sellers and Business Partners"},{"location":"Lab/1-Evaluation/#_1","text":"","title":""},{"location":"Lab/1-Evaluation/#ibmer-stand-deliver-assessment","text":"IBMers \u2014 SUBMIT RECORDINGS HERE Submit your Stand & Deliver recording online using IBM YourLearning: < LINK GOES HERE > The evaluation criteria described below only applies to IBMers , who must record a Stand & Deliver presentation to receive accreditation for this Level 3 course. IBMers will be evaluated by First Line Manager (FLM). Instructions on how to submit a Stand & Deliver are included on this page. IBM Technical Sellers need to include all six of the following elements in their Stand & Deliver recording to receive Level 3 accreditation: Seller articulated client's pain point(s) and the value proposition of using IBM watsonx Code Assistant for Red Hat Ansible Lightspeed . Seller highlighted use cases for IBM watsonx Code Assistant for Red Hat Ansible Lightspeed . Seller demonstrated and discussed several of the key differentiated capabilities of IBM watsonx Code Assistant for Red Hat Ansible Lightspeed that deliver on the value proposition on point one. Seller highlighted benefits to the client (this is the why the client can\u2019t live without these benefits section). Seller highlighted benefits to the client's customers (what will the client be able to deliver to their customers that they could not without this product). Seller closed the demo with a call to action for the client that could include: a workshop, a deeper dive into the product meeting, Proof of Experience (PoX) engagements, and so on.","title":"IBMer Stand &amp; Deliver Assessment"},{"location":"Lab/1-Evaluation/#_2","text":"","title":""},{"location":"Lab/1-Evaluation/#business-partner-quiz-assessment","text":"PARTNERS \u2014 COMPLETE ASSESSMENT HERE Complete your assessment online using IBM Training: < LINK GOES HERE > The accreditation quiz consists of multiple choice questions, with four possible responses (and only one correct answer) for each question.","title":"Business Partner Quiz Assessment"},{"location":"Lab/2-Setup/","text":"Prerequisites and Setup Before getting started, you must install Visual Studio Code (commonly referred to as VS Code ) on your local machine. VS Code is a code editor built on open source technology, free to use, and published by Microsoft. Distributions are available for every major operating system, including Windows and macOS. Download : https://code.visualstudio.com Select the latest \"stable\" release availabe for your machine's operating system. Follow along with the installer wizard steps and continue after VS Code is successfully running on your local machine. Open the VS Code app and locate the sidebar along the left-side of the interface. Click the Extensions icon as shown to open the marketplace of Microsoft services and open source technologies that can be integrated with VS Code. At the top of the Extensions panel is a search bar. Search here for Ansible . Locate from the results the Ansible service published by Red Hat . Click the blue Install icon located to the right. Installation of the Ansible extension for VS Code should only take a moment. You may receive two different prompts during the installation process: Do you trust the authors of the files in this workspace? to which you should respond with Trust Workspace & Install . Do you want to allow untrusted files in this window? to which you should respond with Open . Once the Ansible extension has been successfully added to VS Code, close any \"Welcome\" tabs that open and look for Ansible under the \"Installed\" services in the Extensions panel. DEPRECATED VERSION Ignore the deprecated version of \"Ansible language support\" that was previously published by Tomasz Maciazek. The only official (and installable) Ansible extension is the one published by Red Hat's verified account. To begin experimenting with IBM watsonx Code Assistant for Red Hat Ansible Lightspeed 's generative AI capabilities, you will first need access to some Ansible Playbooks to generate Tasks with. Playbooks have already been prepared ahead of time for the Ansible Lightspeed Technical Preview, which you will make use of here. Click the Explorer button at the top of the left-hand VS Code interface. Depending on your VS Code environment, the Explorer tab will look one of two ways. Click to expand whichever one of the two options best describes your situation and follow the instructions given: I AM NEW TO VS CODE If you are working within a new installation of VS Code, the Explorer tab will display NO FOLDER OPENED and give options to either Open Folder or Clone Repository . Click the Clone Repository button, which will open an executable console at the top of VS Code. You must specify the public GitHub repository from which to \"clone\" the Ansible Lightspeed Technical Preview collection. A clone request in GitHub is essentially a request to replicate code from the cloud-hosted repository into the local (VS Code) environment. Enter into the console the following address and press Return to confirm: https://github.com/craig-br/lightspeed-demos.git I HAVE USED VS CODE BEFORE If you have worked with VS Code before and have added projects or folders to the environment previously, those folders (and their contents) will be displayed within the Explorer tab. However, you still need to clone (replicate) the Ansible Lightspeed Technical Preview collection from GitHub to a folder on your local machine. A \"clone\" request in GitHub is essentially a request to replicate code from the cloud-hosted repository into the local (VS Code and local machine) environment. To perform a clone request with VS Code, do either of the following actions (depending on your operating system): Windows : Press CTRL + Shift + P to open an executable console at the top of VS Code. macOS : Press COMMAND + Shift + P to open an executable console at the top of VS Code. Enter into the console the following instruction and hit Return to confirm: git:clone Now you must specify the public repository from which to clone the data. Copy and paste the following URL into the console and hit Return to confirm: https://github.com/craig-br/lightspeed-demos.git After completing the steps in the expandable window, continue with the instructions that follow down the remainder of this lab guide page. Regardless of which option you chose, the remainder of the steps remain the same. You will be asked to select (using your local machine's file browser) the destination for where the cloned data will be saved locally. Select a directory (Documents, Desktop, or your preference) and then confirm by clicking Select as Repository Destination to kick off the replication from GitHub to your local machine. A prompt will appear asking Would you like to open the cloned repository, or add it to the current workspace? to which you should click Open . You will be asked Do you trust the authors of the files in this folder? to which you should click Yes, I trust the authors . The replication of Ansible Playbooks to your local machine from GitHub is now complete. You can inspect the contents of the repository using the Explorer tab (the first icon in the left-hand navigator), as shown in the following screenshot. LOCAL REPLICAS The replicated/cloned GitHub files are a local replica, meaning that you may safely edit and change the contents of this folder on your local machine without any impact to the master copy on GitHub. Have fun and experiment! Next, you'll need to activate your Ansible Lightspeed Technical Preview extension for VS Code. Return to the Extensions tab that you accessed in Step 1 and look for the installed Ansible extension from the list. Click the mechanical \"cog\" icon (as shown), located on the right side of the Ansible service tile. From the dropdown list of options, click Extension Settings . A settings panel for Ansible will fill the screen. From the top-left corner of the interface, look for a switch to toggle between User and Workspace . Select the Workspace option. Scroll down the list of settings until you locate the fields Ansible > Lightspeed and Ansible > Lightspeed > Suggestions . By default, these will be disabled. Click the checkmark icons to the left of BOTH entries to ENABLE IBM watsonx Code Assistant for Red Hat Ansible Lightspeed Tech Preview features within the VS Code environment. The settings will automatically be applied without needing to confirm or \"save\" manually. Close the Settings tab using the X icon along the top of the taskbar to proceed. Click the Ansible icon from the left-hand interface of the VS Code environment (look for the large \"A\" icon). A panel will open displaying details about Ansible Lightspeed Login . Click the blue Connect button to launch the authorization tool. A prompt will appear stating that The extension Ansible wants to sign in using Ansible Lightspeed to which you should click Allow . You will then be asked about opening an external website, to which you should reply Open . Your web browser will then load to a page asking you to login in using either Red Hat or GitHub. Click the Log in with GitHub option. Accept any license agreements that accompany the log in request. OUTDATED PRODUCT NAMES The branding displayed on this page is an outdated name for the offering before reaching General Availability (GA) status. The correct name is IBM watsonx Code Assistant for Red Hat Ansible Lightspeed . Supply your GitHub account name and password (Step 8). If you have already authenticated using the GitHub extension for VS Code, it may bypass that require entirely. After logging in, you will be asked to Authorize Ansible Lightspeed for VS Code to which you should click Authorize . A prompt will appear inside VS Code asking Allow an extension to open this URI? to which you should click Open . Time to open your first YAML file from the cloned GitHub repository and validate that Ansible Lightspeed has been set up properly. Click the Explorer tab on the top-left corner of the VS Code interface. Drill down into the lightspeed-demos-main/playbooks/infra/install_cockpit/ directory and double-click the demo_install_cockpit.yml YAML file to edit the contents. Look in the bottom-right hand corner of the VS Code editor for a tile labelled Ansible will have appeared. This indicates that Ansible (and Ansible Lightspeed) are now activated for this particular workspace. PYTHON DRIVERS ARE MISSING? The Ansible Lightspeed extension for VS Code requires that Python 3.11.5 be activated as part of the workspace. Look for a Python tile adjacent to the Ansible tile along the bottom-right corner of the VS Code interface. If it is not set, click the tile and select Python 3.11.5 64-bit . Click the gold-colored Select python environment button at the bottom-right of the interface. From the console at the top of the VS Code environment, select the recommended Python 3.11.5 64-bit option and hit Return to confirm. Inspect the bottom-right of the interface again to confirm that the Python library has been set. If you continue to receive errors messages about Ansible-lint is not available or Command failed: ... you can safely ignore those warnings. Click the X icon next to the pop-up to dismiss the messages. Well done. Your VS Code environment is now fully configured and ready for experimentation using generative AI techniques. In the following section, we will review the evaluation criteria for how IBM technical sellers and business partners receive accreditation for completing the Level 3 material.","title":"Setup"},{"location":"Lab/2-Setup/#prerequisites-and-setup","text":"Before getting started, you must install Visual Studio Code (commonly referred to as VS Code ) on your local machine. VS Code is a code editor built on open source technology, free to use, and published by Microsoft. Distributions are available for every major operating system, including Windows and macOS. Download : https://code.visualstudio.com Select the latest \"stable\" release availabe for your machine's operating system. Follow along with the installer wizard steps and continue after VS Code is successfully running on your local machine. Open the VS Code app and locate the sidebar along the left-side of the interface. Click the Extensions icon as shown to open the marketplace of Microsoft services and open source technologies that can be integrated with VS Code. At the top of the Extensions panel is a search bar. Search here for Ansible . Locate from the results the Ansible service published by Red Hat . Click the blue Install icon located to the right. Installation of the Ansible extension for VS Code should only take a moment. You may receive two different prompts during the installation process: Do you trust the authors of the files in this workspace? to which you should respond with Trust Workspace & Install . Do you want to allow untrusted files in this window? to which you should respond with Open . Once the Ansible extension has been successfully added to VS Code, close any \"Welcome\" tabs that open and look for Ansible under the \"Installed\" services in the Extensions panel. DEPRECATED VERSION Ignore the deprecated version of \"Ansible language support\" that was previously published by Tomasz Maciazek. The only official (and installable) Ansible extension is the one published by Red Hat's verified account. To begin experimenting with IBM watsonx Code Assistant for Red Hat Ansible Lightspeed 's generative AI capabilities, you will first need access to some Ansible Playbooks to generate Tasks with. Playbooks have already been prepared ahead of time for the Ansible Lightspeed Technical Preview, which you will make use of here. Click the Explorer button at the top of the left-hand VS Code interface. Depending on your VS Code environment, the Explorer tab will look one of two ways. Click to expand whichever one of the two options best describes your situation and follow the instructions given: I AM NEW TO VS CODE If you are working within a new installation of VS Code, the Explorer tab will display NO FOLDER OPENED and give options to either Open Folder or Clone Repository . Click the Clone Repository button, which will open an executable console at the top of VS Code. You must specify the public GitHub repository from which to \"clone\" the Ansible Lightspeed Technical Preview collection. A clone request in GitHub is essentially a request to replicate code from the cloud-hosted repository into the local (VS Code) environment. Enter into the console the following address and press Return to confirm: https://github.com/craig-br/lightspeed-demos.git I HAVE USED VS CODE BEFORE If you have worked with VS Code before and have added projects or folders to the environment previously, those folders (and their contents) will be displayed within the Explorer tab. However, you still need to clone (replicate) the Ansible Lightspeed Technical Preview collection from GitHub to a folder on your local machine. A \"clone\" request in GitHub is essentially a request to replicate code from the cloud-hosted repository into the local (VS Code and local machine) environment. To perform a clone request with VS Code, do either of the following actions (depending on your operating system): Windows : Press CTRL + Shift + P to open an executable console at the top of VS Code. macOS : Press COMMAND + Shift + P to open an executable console at the top of VS Code. Enter into the console the following instruction and hit Return to confirm: git:clone Now you must specify the public repository from which to clone the data. Copy and paste the following URL into the console and hit Return to confirm: https://github.com/craig-br/lightspeed-demos.git After completing the steps in the expandable window, continue with the instructions that follow down the remainder of this lab guide page. Regardless of which option you chose, the remainder of the steps remain the same. You will be asked to select (using your local machine's file browser) the destination for where the cloned data will be saved locally. Select a directory (Documents, Desktop, or your preference) and then confirm by clicking Select as Repository Destination to kick off the replication from GitHub to your local machine. A prompt will appear asking Would you like to open the cloned repository, or add it to the current workspace? to which you should click Open . You will be asked Do you trust the authors of the files in this folder? to which you should click Yes, I trust the authors . The replication of Ansible Playbooks to your local machine from GitHub is now complete. You can inspect the contents of the repository using the Explorer tab (the first icon in the left-hand navigator), as shown in the following screenshot. LOCAL REPLICAS The replicated/cloned GitHub files are a local replica, meaning that you may safely edit and change the contents of this folder on your local machine without any impact to the master copy on GitHub. Have fun and experiment! Next, you'll need to activate your Ansible Lightspeed Technical Preview extension for VS Code. Return to the Extensions tab that you accessed in Step 1 and look for the installed Ansible extension from the list. Click the mechanical \"cog\" icon (as shown), located on the right side of the Ansible service tile. From the dropdown list of options, click Extension Settings . A settings panel for Ansible will fill the screen. From the top-left corner of the interface, look for a switch to toggle between User and Workspace . Select the Workspace option. Scroll down the list of settings until you locate the fields Ansible > Lightspeed and Ansible > Lightspeed > Suggestions . By default, these will be disabled. Click the checkmark icons to the left of BOTH entries to ENABLE IBM watsonx Code Assistant for Red Hat Ansible Lightspeed Tech Preview features within the VS Code environment. The settings will automatically be applied without needing to confirm or \"save\" manually. Close the Settings tab using the X icon along the top of the taskbar to proceed. Click the Ansible icon from the left-hand interface of the VS Code environment (look for the large \"A\" icon). A panel will open displaying details about Ansible Lightspeed Login . Click the blue Connect button to launch the authorization tool. A prompt will appear stating that The extension Ansible wants to sign in using Ansible Lightspeed to which you should click Allow . You will then be asked about opening an external website, to which you should reply Open . Your web browser will then load to a page asking you to login in using either Red Hat or GitHub. Click the Log in with GitHub option. Accept any license agreements that accompany the log in request. OUTDATED PRODUCT NAMES The branding displayed on this page is an outdated name for the offering before reaching General Availability (GA) status. The correct name is IBM watsonx Code Assistant for Red Hat Ansible Lightspeed . Supply your GitHub account name and password (Step 8). If you have already authenticated using the GitHub extension for VS Code, it may bypass that require entirely. After logging in, you will be asked to Authorize Ansible Lightspeed for VS Code to which you should click Authorize . A prompt will appear inside VS Code asking Allow an extension to open this URI? to which you should click Open . Time to open your first YAML file from the cloned GitHub repository and validate that Ansible Lightspeed has been set up properly. Click the Explorer tab on the top-left corner of the VS Code interface. Drill down into the lightspeed-demos-main/playbooks/infra/install_cockpit/ directory and double-click the demo_install_cockpit.yml YAML file to edit the contents. Look in the bottom-right hand corner of the VS Code editor for a tile labelled Ansible will have appeared. This indicates that Ansible (and Ansible Lightspeed) are now activated for this particular workspace. PYTHON DRIVERS ARE MISSING? The Ansible Lightspeed extension for VS Code requires that Python 3.11.5 be activated as part of the workspace. Look for a Python tile adjacent to the Ansible tile along the bottom-right corner of the VS Code interface. If it is not set, click the tile and select Python 3.11.5 64-bit . Click the gold-colored Select python environment button at the bottom-right of the interface. From the console at the top of the VS Code environment, select the recommended Python 3.11.5 64-bit option and hit Return to confirm. Inspect the bottom-right of the interface again to confirm that the Python library has been set. If you continue to receive errors messages about Ansible-lint is not available or Command failed: ... you can safely ignore those warnings. Click the X icon next to the pop-up to dismiss the messages. Well done. Your VS Code environment is now fully configured and ready for experimentation using generative AI techniques. In the following section, we will review the evaluation criteria for how IBM technical sellers and business partners receive accreditation for completing the Level 3 material.","title":"Prerequisites and Setup"},{"location":"Lab/3-Generating-Code/","text":"Generating Code with IBM watsonx Code Assistant for Red Hat Ansible Lightspeed In the following section, you will experiment with three of the key capabilities of IBM watsonx Code Assistant for Red Hat Ansible Lightspeed : AI-generated code recommendations Content source matching and source attribution Post-processing of AI-generated code for adherence to best practices Once you have learned the fundamentals of generating Task code blocks, you'll be ready to shape the AI-generated code recommendations in the Customizing Tasks module and automate the deployment of a full infrastructure stack in the concluding Deploying an AWS EC2 Instance and WordPress Application module. ANSIBLE TASKS At the time of publication, IBM watsonx Code Assistant for Red Hat Ansible Lightspeed can only generate code for Ansible Tasks . In future releases, it will be capable of generating many other components of Ansible Playbooks. The process of creating AI-generated code recommendations is as simple as modifying the natural language (plain English) Task descriptions of Ansible jobs, which always start with - name: and followed by some description of the task to be performed. They are often preceded with some # comments or documentation \u2014 particularly inside the Technical Preview assets. After the natural language description of the automation Task has been set, Generative AI handles the rest. Let's begin by returning to the Technical Preview lightspeed-demos-main/playbooks/infra/install_cockpit/demo_install_cockpit.yml YAML file that you opened in the VS Code editor as part of the Setup lab module. lightspeed-demos-main/playbooks/infra/install_cockpit/demo_install_cockpit.yml 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 --- - name : Install and configure Cockpit hosts : rhel become : true # module_defaults: # ansible.builtin.service: # enabled: true # state: started tasks : # TASK 1 # # 1a. Uncomment task description below and generate a task suggestion. # # Note - The suggestion included Ansible best practices by using Fully Qualified Collection name. # - name: Install cockpit package # TASK 2 # # 2a. Uncomment task description below and generate a task suggestion. # # Note - Ansible Lightspeed used \"ansible.builtin.template\" module based on the \".j2\" file extension. # # Note - The suggestion set the file permissions (\"0644\"), owner, and group based on Ansible best practices. # - name: Copy cockpit.conf.j2 to /etc/cockpit # TASK 3 # # 3a. Uncomment task description below and generate a task suggestion. # # Note - Ansible Lightspeed used the generic \"Start and enable service\" prompt # # and full Playbook context to infer the recommendation should start the \"cockpit\" service. # # 3b. Uncomment the \"module_defaults\" section at the top of the Playbook. # # 3c. Clear current task suggestion and request updated suggestion. # # Note - Ansible Lightspeed used the full Playbook context and evaluated the \"module_defaults\" # # when generating a suggestion. # # The updated suggestion no longer includes \"enabled:\" and \"state:\" arguments. # - name: Start and enable service # TASK 4 # # 4a. Uncomment task description below and generate an Ansible Playbook task suggestion. # # 4b. Save the Playbook. # - name: Wait 15 seconds port 9090 The Playbook code above warrants some explanation before we move on with modifications: Line 2 essentially marks the beginning of the Playbook instructions, the purpose of which is to automate the process of installing and configuring Cockpit for Red Hat Ansible. Lines 2-3 define variables that will remain static throughout the remainder of the Playbook. These variables will be referenced by the AI-generated code suggestions at a later stage. This is a key capability of the offering and one which we will go into much finer details on later. Lines 6-9 are variables which have been commented out and therefore are invisible to the execution of the Ansible script and not examined by Ansible Lightspeed for context when generating code recommendations. We will experiment shortly with how removing the # comment blocks impacts the recommendations of task block code. \"Uncommenting\" these lines of code will make them viable for execution and these lines will afterwards be considered as valid Playbook \"context\" for AI code generation. Locate TASK 1 on Line 15 of the YAML file, which handles installation of Cockpit for Ansible. # - name: Install cockpit package Pay attention to the indentation and characters used on Line 15, which in sequence from left to right are as follows: begins with a TAB indentation a # character to \"comment out\" the line contents a whitespace SPACE character - name: which signifies the start of a Task definition and finally the natural language description of the Task To generate code for the Task using Ansible Lightspeed, first uncomment the line of code (remove # characters from the start of a line). Highlight the line(s) of code you wish to uncomment and then press CMD + / for macOS or CTRL + / for Windows. You can repeat those keystrokes with the line(s) selected to toggle between commenting or uncommenting lines of code. INDENTATION LEVELS AND WHITESPACE Ansible and YAML Playbooks are very sensitive to whitespacing and indentation. Indentations (such as the TAB in this example) denote different hierarchies and code nesting levels within the YAML structure. You can use whitespaces instead of TAB if you prefer, but be sure to keep your indentations consistent: keep using TAB or whitespaces for indenting lines of code, but don't intermix the two. Afterwards, Line 15 should look like the following \u2014 beginning with a single TAB indentation: - name : Install cockpit package Now you are ready to begin generating code. Place your cursor at the end of Line 15 and hit Return . Wait for Ansible Lightspeed to engage and generate the suggested (in italicized text ) code blocks for executing the task. This temporary code suggestion is entirely generated by AI. As a user, you have the option to either accept the code recommendation as-given by pressing TAB on your keyboard OR you can modify the recommended code by highlighting and replacing the italicized text. Hit TAB to accept the suggested code and then compare with the SOLUTION tab below. TEMPLATE SOLUTION # TASK 1 - name : Install cockpit package # TASK 1 - name : Install cockpit package ansible.builtin.package : name : cockpit state : present As part of the plain-text description of the Task, Ansible Lightspeed was asked to include the \u201ccockpit\u201d Role, part of the Red Hat Enterprise Linux System Roles Certified Content Collection. The AI-generated code suggestion invoked the Fully Qualified Collection Name ( FQCN ) - ansible.builtin.package . Making use of FQCNs where possible is a recommended best practice and is a prime example of the many ways in which the offering infuses post-processing capabilities within the AI-generated code produced by IBM watsonx Code Assistant for Red Hat Ansible Lightspeed . Additional examples of infusing best-practices into AI-generated code recommendations can be found in the following Task 2 ( Line 21 ). Generate the task code block as you did previously and once again compare your results with the SOLUTION tab below. TEMPLATE SOLUTION # TASK 2 - name : Copy cockpit.conf.j2 to /etc/cockpit # TASK 2 - name : Copy cockpit.conf.j2 to /etc/cockpit ansible.builtin.template : src : cockpit.conf.j2 dest : /etc/cockpit/cockpit.conf owner : root group : root mode : '0644' The AI-generated code recommendation will copy cockpit.conf to the target host. Take note of the fact that the recommendation included the mode: argument and set the Linux file permissions to 0644 , neither of which were things explicitly requested in the Task -name description, but are both additions which adhere to best practices around defining Ansible automaton tasks. These additional recommendations stem from a robust example of setting file permissions for the ansible.builtin.copy module, a recommended best practice from the Ansible Galaxy and Red Hat communities that Lightspeed carried into this AI-generated code recommendation as well. You may continue generating Task blocks on this Playbook if you wish \u2014 this is optional, as you will not be returning to this Playbook at a later time. When ready to proceed, follow along with the lab documentation below. Content source matching and attribution attempts to match code recommendations to Ansible Galaxy sources (projects and contributors) for data provenance. A powerful capability within IBM watsonx Code Assistant for Red Hat Ansible Lightspeed is Content Source Matching (often referred to as \"code explainability\"), which attempts to match AI-generated code suggestions to the training data and sources that were utilized in generating the suggested Task code. For the Technical Preview (pre-GA) release of the service, the extent of these capabilities are fairly rudimentary: identifying Ansible Galaxy packages and contributors, where available, for each line of AI-generated code. These code attribution suggestions are created using a k-NN ( K-Nearest Neighbors ) algorithm that examines Ansible Galaxy and training data repositories in search of the nearest related content to the AI-generated code suggestions. PROJECTED CAPABILITIES In the future, it is anticipated that clients will be able to supply Ansible Lightspeed with a Playbook and ask \"where did this generated code come from and who was its author?\" The service may potentially gain the ability to \"comment\" and document lines (or blocks) of code, explaining to users in plain English what functions the code is performing \u2014 work traditionally left to the developer or author, but an area which is nevertheless often neglected or lacking in many organization's code bases. To enable Content Source Matching capabilities within Ansible Lightspeed, navigate to the main menu bar (very top of your screen) for VS Code and drill down into View > Open View... as shown below. The console along the top of the VS Code interface will now activate, awaiting a prompt. Enter view Lightspeed Training Matches and hit the Return key to confirm the selection. At this point, all future generative AI tasks\u2014 such as asking Ansible Lightspeed to generate the code for a Task \u2014will now open a panel at the bottom of the VS Code interface displaying a variety of options: Problems , Output , Debug Console , Terminal , Ports , Comments , and most importantly Ansible:Lightspeed Training Matches . Let's experiment with generating some lines of code and inspecting the Ansible:Lightspeed Training Matches tab to observe this code explainability feature in action. Open the following Ansible Playbook within your Lightspeed repository, or copy and paste the following code template into a New File... within your VS Code environment. lightspeed-demos-main/playbooks/infra/install_pgsql_and_pgadmin/demo_install_pgsql.yml 1 2 3 4 5 6 7 8 9 10 11 --- - name : Configure Database servers hosts : databases become : true tasks : - name : Install postgresql-server - name : Run postgresql setup command - name : Start and enable postgresql service Within your VS Code environment, attempt to generate code for the task on Line 7 . The resulting code should look like the following: - name : Install postgresql-server ansible.builtin.package : name : postgresql-server state : present Of particular interest to us at this time is the code attribution details associated with this recommendation, which will be appearing in the panel at the bottom of the VS Code interface once the code recommendation is finalized. You will need to accept the AI-generated code suggestions (using the TAB key) before the content source matching tab will populate with details about the code's origins. The three most likely content sources used in training the IBM watsonx Code Assistant for Red Hat Ansible Lightspeed model\u2014 which produced the AI-generated code recommendations \u2014are listed within the Training Matches tab. Clicking the arrow icon to the left of each attribution will expand further details about the source. Information about the URL , Path , Data Source , License , Ansible Type , and Score will be presented (where available) under each listing. Red Hat-certified and maintained collections, as well as contributors to open source projects on Ansible Galaxy, are the primary sources for Ansible Lightspeed model training and are the content sources you are most likely to see matched to AI-generated code recommendations. BROKEN LINKS TO ANSIBLE GALAXY As of October 3, 2023, Red Hat has been revamping the API endpoints for Ansible Galaxy and the Technical Preview for Ansible Lightspeed has not yet been updated to reflect these changes. The result may be that URL shortcuts generated by the Training Matches tabs redirect to missing pages on Ansible Galaxy. These issues will be ironed out in a future release of the Technical Preview or full General Availability (GA) code. Drilling down into the URL field will redirect your web browser back to the precise collections and sources on Ansible Galaxy from which the code recommendations were derived. Here you can learn much richer details about the status of the project, any associated open source repositories involved (such as GitHub), contributions and activities ongoing with the code base, the author(s) involved, and many more intricacies. Post-processing of Task descriptions and YAML file contents helps generate contextually aware, accurate Ansible content suggestions. Another element of code generation that Ansible Lightspeed excels at is understanding context within the Playbook it is executing against. If a variable or attribute is defined earlier within that Playbook, it will be recalled and referenced\u2014 where it makes sense to do so \u2014in the generation of subsequent lines of code. You may have noticed this already in your experimentations with AI-generated code suggestions. However, one way for us to make this feature quite obvious is to take a previously-generated block of Task code, update the value assigned to a named variable earlier in the Playbook, and then regenerate the Task block. In theory, the newly-generated Task block will use the updated variable name (and differ from how the code block was originally generated). Test out this theory by first examining Line 26 and Line 33 of the following demo_provision_ec2_instance.yml Playbook: lightspeed-demos-main/playbooks/cloud/aws/demo_provision_ec2_instance.yml 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 --- - name : EC2 Cloud Operations hosts : localhost connection : local gather_facts : false module_defaults : group/aws : region : us-east-1 # vars: # ec2_instance: # name: lightspeed-instance-01 # key_name: lightspeed-keypair # image_id: ami-016eb5d644c333ccb # RHEL 9 us-east-1 # tags: # function: lightspeed-demo # security_group: secgroup-lightspeed tasks : # TASK 1 # # 1a. Uncomment task description below and generate a task suggestion. # # Note - Best practices: The suggestion used the Fully Qualified Collection name. # # Note - Context: Ansible Lightspeed used the Playbook name \"EC2 Cloud Operations\" to use the correct \"amazon.aws.ec2_vpc_subnet_info\" module. - name : Gather subnet info tag:Name subnet-lightspeed # TASK 2 # # 2a. Uncomment task description below and generate a task suggestion. # # Note - Context: The suggestion included the previous task's registered variable in the suggestion. # # Note - Accuracy: The suggestion provides the correct key value from the previously task's registered variable. - name : Create vpc_subnet_id var # TASK 3 # # 3a. Uncomment task description \"Provision t3.micro instance\" below and generate a task suggestion. # # Note - Efficiency: The suggestion provides practical variable examples to improve efficiency. - name : Provision t3.micro instance # # 3b. Remove the above task and suggestion. # # Uncomment 2nd task description \"Provision t3.micro instance using ec2_instance var\". # # Generate an updated suggestion. # # Note - Context: The updated suggestion includes the \"ec2_instance variable fields in the suggestion\" - name : Provision t3.micro instance using ec2_instance var TASK 1 (Line 26) and TASK 2 (Line 33) are responsible for gathering information about a subnet that is to be provisioned and then creating a VPC definition based on those details. The first round of AI-generated code for the task on Line 26 produces a code block with a register: subnet_info line \u2014 the result of which is to assign this record to a variable named subnet_info . Nothing terribly complicated or surprising about that. The AI-generated code that follows for the task on Line 33 recommends a code block with vpc_subnet_id: \"{ { subnet_info.subnets[0].subnet_id } }\" as the value associated with the VPC's subnet ID. Critically, the variable subnet_info that was generated in the previous Task is also referenced in the second Task. This demonstrates the contextual awareness of Ansible Lightspeed in action. But we may further validate this capability by changing the name of the variable that was generated from the task on Line 26 and observing how the task block on Line 33 is altered after deleting the previously-generated TASK 2 content and re-generating the code block. Change the name of variable subnet_info instead to subnet_name , delete the code block recommendations under Line 33 , and then regenerate the task on Line 33 . You will immediately notice that the new block of task code references the variable subnet_name that was modified just a moment ago. Once again, Ansible Lightspeed has generated code suggestions that take into account the altered context and variables of the Playbook. Try adjusting other variables within the Playbook and test how these modifications impact the generation of later blocks of Task code in the Playbook. In the following section, you will begin experimentating with customized Ansible Playbooks and testing how changes to Ansible Task natural language descriptions impacts the recommended code produced by Generative AI. Before continuing, it's worth reading up on how the Technical Preview for Ansible Lightspeed extension within VS Code collects data for training and improvement purposes \u2014 something known as telemetry data collection . It is something to be mindful of before creating your own customized Playbooks or supplying your own code for testing purposes. CLICK FOR MORE \u2014 TELEMETRY DATA COLLECTION IBM and Red Hat strongly advocate for and put into practice full transparency about what content is collected\u2014 what is known as \" telemetry data \" \u2014to improve the quality of service for AI offerings such as IBM watsonx Code Assistant for Red Hat Ansible Lightspeed . The service automatically collects recommendations, usage telemetry, and Ansible Playbook state through automated events. IBM watsonx Code Assistant for Red Hat Ansible Lightspeed telemetry is used to improve the service over time. Telemetry data that is collected will be shared with Red Hat and IBM. Clients can opt out of this data sharing by disabling (within VS Code) the IBM watsonx Code Assistant for Red Hat Ansible Lightspeed setting in the Ansible VS Code extension. Opting-out of telemetry data sharing does not remove telemetry data already sent to Red Hat and IBM. The telemetry data shared with Red Hat and IBM are selected to be anonymized where applicable and as unobtrusive as possible. Metrics collected include the following: Recommendation accepted/rejected : Captured to indicate whether an AI-generated content suggestion was accepted by the user to include in the actively developed Playbook. Task prompt : The contents of the name property (ie. the natural language prompted by the user) of the task used to request a recommendation from IBM watsonx Code Assistant for Red Hat Ansible Lightspeed . Playbook/Role context : The contents of a Playbook file that exist prior to the task prompt used in the current recommendation. This is used to provide additional context for a recommendation \u2014 in addition to what the natural language task prompt provides. Potentially sensitive information is first removed before collection as telemetry data. Playbook/Role state : This data point is captured at various stages, before and after, the AI-generated recommendation is presented to the user. \"State\" encompasses the contents of an Ansible Playbook. This is captured to help the service understand what components of a recommendation were valuable (or not) once a recommendation is provided. Anonymized document Uniform Resource Identifier (URI) : Used to determine the kind of Ansible document (Playbook, Role, or so on). Request and response timestamps : Captured in UTC format. Anonymized user ID : Captured at (~/.redhat/anonymousid). Anonymized suggestion ID : Automatically generated session ID associated with service request. Telemetry data may be kept indefinitely for product improvement. Users are not able to request that their telemetry be purged. Clients may disable the Ansible Lightspeed service to prevent further telemetry from being sent to the service. Red Hat and IBM do not claim any copyright or other intellectual property rights to the suggestions generated by IBM watsonx Code Assistant for Red Hat Ansible Lightspeed . Additional details can be located within the Terms of Service for the offering: https://docs.ai.ansible.redhat.com/tos/","title":"Generating Code"},{"location":"Lab/3-Generating-Code/#generating-code-with-ibm-watsonx-code-assistant-for-red-hat-ansible-lightspeed","text":"In the following section, you will experiment with three of the key capabilities of IBM watsonx Code Assistant for Red Hat Ansible Lightspeed : AI-generated code recommendations Content source matching and source attribution Post-processing of AI-generated code for adherence to best practices Once you have learned the fundamentals of generating Task code blocks, you'll be ready to shape the AI-generated code recommendations in the Customizing Tasks module and automate the deployment of a full infrastructure stack in the concluding Deploying an AWS EC2 Instance and WordPress Application module. ANSIBLE TASKS At the time of publication, IBM watsonx Code Assistant for Red Hat Ansible Lightspeed can only generate code for Ansible Tasks . In future releases, it will be capable of generating many other components of Ansible Playbooks. The process of creating AI-generated code recommendations is as simple as modifying the natural language (plain English) Task descriptions of Ansible jobs, which always start with - name: and followed by some description of the task to be performed. They are often preceded with some # comments or documentation \u2014 particularly inside the Technical Preview assets. After the natural language description of the automation Task has been set, Generative AI handles the rest. Let's begin by returning to the Technical Preview lightspeed-demos-main/playbooks/infra/install_cockpit/demo_install_cockpit.yml YAML file that you opened in the VS Code editor as part of the Setup lab module. lightspeed-demos-main/playbooks/infra/install_cockpit/demo_install_cockpit.yml 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 --- - name : Install and configure Cockpit hosts : rhel become : true # module_defaults: # ansible.builtin.service: # enabled: true # state: started tasks : # TASK 1 # # 1a. Uncomment task description below and generate a task suggestion. # # Note - The suggestion included Ansible best practices by using Fully Qualified Collection name. # - name: Install cockpit package # TASK 2 # # 2a. Uncomment task description below and generate a task suggestion. # # Note - Ansible Lightspeed used \"ansible.builtin.template\" module based on the \".j2\" file extension. # # Note - The suggestion set the file permissions (\"0644\"), owner, and group based on Ansible best practices. # - name: Copy cockpit.conf.j2 to /etc/cockpit # TASK 3 # # 3a. Uncomment task description below and generate a task suggestion. # # Note - Ansible Lightspeed used the generic \"Start and enable service\" prompt # # and full Playbook context to infer the recommendation should start the \"cockpit\" service. # # 3b. Uncomment the \"module_defaults\" section at the top of the Playbook. # # 3c. Clear current task suggestion and request updated suggestion. # # Note - Ansible Lightspeed used the full Playbook context and evaluated the \"module_defaults\" # # when generating a suggestion. # # The updated suggestion no longer includes \"enabled:\" and \"state:\" arguments. # - name: Start and enable service # TASK 4 # # 4a. Uncomment task description below and generate an Ansible Playbook task suggestion. # # 4b. Save the Playbook. # - name: Wait 15 seconds port 9090 The Playbook code above warrants some explanation before we move on with modifications: Line 2 essentially marks the beginning of the Playbook instructions, the purpose of which is to automate the process of installing and configuring Cockpit for Red Hat Ansible. Lines 2-3 define variables that will remain static throughout the remainder of the Playbook. These variables will be referenced by the AI-generated code suggestions at a later stage. This is a key capability of the offering and one which we will go into much finer details on later. Lines 6-9 are variables which have been commented out and therefore are invisible to the execution of the Ansible script and not examined by Ansible Lightspeed for context when generating code recommendations. We will experiment shortly with how removing the # comment blocks impacts the recommendations of task block code. \"Uncommenting\" these lines of code will make them viable for execution and these lines will afterwards be considered as valid Playbook \"context\" for AI code generation. Locate TASK 1 on Line 15 of the YAML file, which handles installation of Cockpit for Ansible. # - name: Install cockpit package Pay attention to the indentation and characters used on Line 15, which in sequence from left to right are as follows: begins with a TAB indentation a # character to \"comment out\" the line contents a whitespace SPACE character - name: which signifies the start of a Task definition and finally the natural language description of the Task To generate code for the Task using Ansible Lightspeed, first uncomment the line of code (remove # characters from the start of a line). Highlight the line(s) of code you wish to uncomment and then press CMD + / for macOS or CTRL + / for Windows. You can repeat those keystrokes with the line(s) selected to toggle between commenting or uncommenting lines of code. INDENTATION LEVELS AND WHITESPACE Ansible and YAML Playbooks are very sensitive to whitespacing and indentation. Indentations (such as the TAB in this example) denote different hierarchies and code nesting levels within the YAML structure. You can use whitespaces instead of TAB if you prefer, but be sure to keep your indentations consistent: keep using TAB or whitespaces for indenting lines of code, but don't intermix the two. Afterwards, Line 15 should look like the following \u2014 beginning with a single TAB indentation: - name : Install cockpit package Now you are ready to begin generating code. Place your cursor at the end of Line 15 and hit Return . Wait for Ansible Lightspeed to engage and generate the suggested (in italicized text ) code blocks for executing the task. This temporary code suggestion is entirely generated by AI. As a user, you have the option to either accept the code recommendation as-given by pressing TAB on your keyboard OR you can modify the recommended code by highlighting and replacing the italicized text. Hit TAB to accept the suggested code and then compare with the SOLUTION tab below. TEMPLATE SOLUTION # TASK 1 - name : Install cockpit package # TASK 1 - name : Install cockpit package ansible.builtin.package : name : cockpit state : present As part of the plain-text description of the Task, Ansible Lightspeed was asked to include the \u201ccockpit\u201d Role, part of the Red Hat Enterprise Linux System Roles Certified Content Collection. The AI-generated code suggestion invoked the Fully Qualified Collection Name ( FQCN ) - ansible.builtin.package . Making use of FQCNs where possible is a recommended best practice and is a prime example of the many ways in which the offering infuses post-processing capabilities within the AI-generated code produced by IBM watsonx Code Assistant for Red Hat Ansible Lightspeed . Additional examples of infusing best-practices into AI-generated code recommendations can be found in the following Task 2 ( Line 21 ). Generate the task code block as you did previously and once again compare your results with the SOLUTION tab below. TEMPLATE SOLUTION # TASK 2 - name : Copy cockpit.conf.j2 to /etc/cockpit # TASK 2 - name : Copy cockpit.conf.j2 to /etc/cockpit ansible.builtin.template : src : cockpit.conf.j2 dest : /etc/cockpit/cockpit.conf owner : root group : root mode : '0644' The AI-generated code recommendation will copy cockpit.conf to the target host. Take note of the fact that the recommendation included the mode: argument and set the Linux file permissions to 0644 , neither of which were things explicitly requested in the Task -name description, but are both additions which adhere to best practices around defining Ansible automaton tasks. These additional recommendations stem from a robust example of setting file permissions for the ansible.builtin.copy module, a recommended best practice from the Ansible Galaxy and Red Hat communities that Lightspeed carried into this AI-generated code recommendation as well. You may continue generating Task blocks on this Playbook if you wish \u2014 this is optional, as you will not be returning to this Playbook at a later time. When ready to proceed, follow along with the lab documentation below.","title":"Generating Code with IBM watsonx Code Assistant for Red Hat Ansible Lightspeed"},{"location":"Lab/3-Generating-Code/#_1","text":"","title":""},{"location":"Lab/3-Generating-Code/#content-source-matching-and-attribution-attempts-to-match-code-recommendations-to-ansible-galaxy-sources-projects-and-contributors-for-data-provenance","text":"A powerful capability within IBM watsonx Code Assistant for Red Hat Ansible Lightspeed is Content Source Matching (often referred to as \"code explainability\"), which attempts to match AI-generated code suggestions to the training data and sources that were utilized in generating the suggested Task code. For the Technical Preview (pre-GA) release of the service, the extent of these capabilities are fairly rudimentary: identifying Ansible Galaxy packages and contributors, where available, for each line of AI-generated code. These code attribution suggestions are created using a k-NN ( K-Nearest Neighbors ) algorithm that examines Ansible Galaxy and training data repositories in search of the nearest related content to the AI-generated code suggestions. PROJECTED CAPABILITIES In the future, it is anticipated that clients will be able to supply Ansible Lightspeed with a Playbook and ask \"where did this generated code come from and who was its author?\" The service may potentially gain the ability to \"comment\" and document lines (or blocks) of code, explaining to users in plain English what functions the code is performing \u2014 work traditionally left to the developer or author, but an area which is nevertheless often neglected or lacking in many organization's code bases. To enable Content Source Matching capabilities within Ansible Lightspeed, navigate to the main menu bar (very top of your screen) for VS Code and drill down into View > Open View... as shown below. The console along the top of the VS Code interface will now activate, awaiting a prompt. Enter view Lightspeed Training Matches and hit the Return key to confirm the selection. At this point, all future generative AI tasks\u2014 such as asking Ansible Lightspeed to generate the code for a Task \u2014will now open a panel at the bottom of the VS Code interface displaying a variety of options: Problems , Output , Debug Console , Terminal , Ports , Comments , and most importantly Ansible:Lightspeed Training Matches . Let's experiment with generating some lines of code and inspecting the Ansible:Lightspeed Training Matches tab to observe this code explainability feature in action. Open the following Ansible Playbook within your Lightspeed repository, or copy and paste the following code template into a New File... within your VS Code environment. lightspeed-demos-main/playbooks/infra/install_pgsql_and_pgadmin/demo_install_pgsql.yml 1 2 3 4 5 6 7 8 9 10 11 --- - name : Configure Database servers hosts : databases become : true tasks : - name : Install postgresql-server - name : Run postgresql setup command - name : Start and enable postgresql service Within your VS Code environment, attempt to generate code for the task on Line 7 . The resulting code should look like the following: - name : Install postgresql-server ansible.builtin.package : name : postgresql-server state : present Of particular interest to us at this time is the code attribution details associated with this recommendation, which will be appearing in the panel at the bottom of the VS Code interface once the code recommendation is finalized. You will need to accept the AI-generated code suggestions (using the TAB key) before the content source matching tab will populate with details about the code's origins. The three most likely content sources used in training the IBM watsonx Code Assistant for Red Hat Ansible Lightspeed model\u2014 which produced the AI-generated code recommendations \u2014are listed within the Training Matches tab. Clicking the arrow icon to the left of each attribution will expand further details about the source. Information about the URL , Path , Data Source , License , Ansible Type , and Score will be presented (where available) under each listing. Red Hat-certified and maintained collections, as well as contributors to open source projects on Ansible Galaxy, are the primary sources for Ansible Lightspeed model training and are the content sources you are most likely to see matched to AI-generated code recommendations. BROKEN LINKS TO ANSIBLE GALAXY As of October 3, 2023, Red Hat has been revamping the API endpoints for Ansible Galaxy and the Technical Preview for Ansible Lightspeed has not yet been updated to reflect these changes. The result may be that URL shortcuts generated by the Training Matches tabs redirect to missing pages on Ansible Galaxy. These issues will be ironed out in a future release of the Technical Preview or full General Availability (GA) code. Drilling down into the URL field will redirect your web browser back to the precise collections and sources on Ansible Galaxy from which the code recommendations were derived. Here you can learn much richer details about the status of the project, any associated open source repositories involved (such as GitHub), contributions and activities ongoing with the code base, the author(s) involved, and many more intricacies.","title":"Content source matching and attribution attempts to match code recommendations to Ansible Galaxy sources (projects and contributors) for data provenance."},{"location":"Lab/3-Generating-Code/#_2","text":"","title":""},{"location":"Lab/3-Generating-Code/#post-processing-of-task-descriptions-and-yaml-file-contents-helps-generate-contextually-aware-accurate-ansible-content-suggestions","text":"Another element of code generation that Ansible Lightspeed excels at is understanding context within the Playbook it is executing against. If a variable or attribute is defined earlier within that Playbook, it will be recalled and referenced\u2014 where it makes sense to do so \u2014in the generation of subsequent lines of code. You may have noticed this already in your experimentations with AI-generated code suggestions. However, one way for us to make this feature quite obvious is to take a previously-generated block of Task code, update the value assigned to a named variable earlier in the Playbook, and then regenerate the Task block. In theory, the newly-generated Task block will use the updated variable name (and differ from how the code block was originally generated). Test out this theory by first examining Line 26 and Line 33 of the following demo_provision_ec2_instance.yml Playbook: lightspeed-demos-main/playbooks/cloud/aws/demo_provision_ec2_instance.yml 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 --- - name : EC2 Cloud Operations hosts : localhost connection : local gather_facts : false module_defaults : group/aws : region : us-east-1 # vars: # ec2_instance: # name: lightspeed-instance-01 # key_name: lightspeed-keypair # image_id: ami-016eb5d644c333ccb # RHEL 9 us-east-1 # tags: # function: lightspeed-demo # security_group: secgroup-lightspeed tasks : # TASK 1 # # 1a. Uncomment task description below and generate a task suggestion. # # Note - Best practices: The suggestion used the Fully Qualified Collection name. # # Note - Context: Ansible Lightspeed used the Playbook name \"EC2 Cloud Operations\" to use the correct \"amazon.aws.ec2_vpc_subnet_info\" module. - name : Gather subnet info tag:Name subnet-lightspeed # TASK 2 # # 2a. Uncomment task description below and generate a task suggestion. # # Note - Context: The suggestion included the previous task's registered variable in the suggestion. # # Note - Accuracy: The suggestion provides the correct key value from the previously task's registered variable. - name : Create vpc_subnet_id var # TASK 3 # # 3a. Uncomment task description \"Provision t3.micro instance\" below and generate a task suggestion. # # Note - Efficiency: The suggestion provides practical variable examples to improve efficiency. - name : Provision t3.micro instance # # 3b. Remove the above task and suggestion. # # Uncomment 2nd task description \"Provision t3.micro instance using ec2_instance var\". # # Generate an updated suggestion. # # Note - Context: The updated suggestion includes the \"ec2_instance variable fields in the suggestion\" - name : Provision t3.micro instance using ec2_instance var TASK 1 (Line 26) and TASK 2 (Line 33) are responsible for gathering information about a subnet that is to be provisioned and then creating a VPC definition based on those details. The first round of AI-generated code for the task on Line 26 produces a code block with a register: subnet_info line \u2014 the result of which is to assign this record to a variable named subnet_info . Nothing terribly complicated or surprising about that. The AI-generated code that follows for the task on Line 33 recommends a code block with vpc_subnet_id: \"{ { subnet_info.subnets[0].subnet_id } }\" as the value associated with the VPC's subnet ID. Critically, the variable subnet_info that was generated in the previous Task is also referenced in the second Task. This demonstrates the contextual awareness of Ansible Lightspeed in action. But we may further validate this capability by changing the name of the variable that was generated from the task on Line 26 and observing how the task block on Line 33 is altered after deleting the previously-generated TASK 2 content and re-generating the code block. Change the name of variable subnet_info instead to subnet_name , delete the code block recommendations under Line 33 , and then regenerate the task on Line 33 . You will immediately notice that the new block of task code references the variable subnet_name that was modified just a moment ago. Once again, Ansible Lightspeed has generated code suggestions that take into account the altered context and variables of the Playbook. Try adjusting other variables within the Playbook and test how these modifications impact the generation of later blocks of Task code in the Playbook. In the following section, you will begin experimentating with customized Ansible Playbooks and testing how changes to Ansible Task natural language descriptions impacts the recommended code produced by Generative AI. Before continuing, it's worth reading up on how the Technical Preview for Ansible Lightspeed extension within VS Code collects data for training and improvement purposes \u2014 something known as telemetry data collection . It is something to be mindful of before creating your own customized Playbooks or supplying your own code for testing purposes. CLICK FOR MORE \u2014 TELEMETRY DATA COLLECTION IBM and Red Hat strongly advocate for and put into practice full transparency about what content is collected\u2014 what is known as \" telemetry data \" \u2014to improve the quality of service for AI offerings such as IBM watsonx Code Assistant for Red Hat Ansible Lightspeed . The service automatically collects recommendations, usage telemetry, and Ansible Playbook state through automated events. IBM watsonx Code Assistant for Red Hat Ansible Lightspeed telemetry is used to improve the service over time. Telemetry data that is collected will be shared with Red Hat and IBM. Clients can opt out of this data sharing by disabling (within VS Code) the IBM watsonx Code Assistant for Red Hat Ansible Lightspeed setting in the Ansible VS Code extension. Opting-out of telemetry data sharing does not remove telemetry data already sent to Red Hat and IBM. The telemetry data shared with Red Hat and IBM are selected to be anonymized where applicable and as unobtrusive as possible. Metrics collected include the following: Recommendation accepted/rejected : Captured to indicate whether an AI-generated content suggestion was accepted by the user to include in the actively developed Playbook. Task prompt : The contents of the name property (ie. the natural language prompted by the user) of the task used to request a recommendation from IBM watsonx Code Assistant for Red Hat Ansible Lightspeed . Playbook/Role context : The contents of a Playbook file that exist prior to the task prompt used in the current recommendation. This is used to provide additional context for a recommendation \u2014 in addition to what the natural language task prompt provides. Potentially sensitive information is first removed before collection as telemetry data. Playbook/Role state : This data point is captured at various stages, before and after, the AI-generated recommendation is presented to the user. \"State\" encompasses the contents of an Ansible Playbook. This is captured to help the service understand what components of a recommendation were valuable (or not) once a recommendation is provided. Anonymized document Uniform Resource Identifier (URI) : Used to determine the kind of Ansible document (Playbook, Role, or so on). Request and response timestamps : Captured in UTC format. Anonymized user ID : Captured at (~/.redhat/anonymousid). Anonymized suggestion ID : Automatically generated session ID associated with service request. Telemetry data may be kept indefinitely for product improvement. Users are not able to request that their telemetry be purged. Clients may disable the Ansible Lightspeed service to prevent further telemetry from being sent to the service. Red Hat and IBM do not claim any copyright or other intellectual property rights to the suggestions generated by IBM watsonx Code Assistant for Red Hat Ansible Lightspeed . Additional details can be located within the Terms of Service for the offering: https://docs.ai.ansible.redhat.com/tos/","title":"Post-processing of Task descriptions and YAML file contents helps generate contextually aware, accurate Ansible content suggestions."},{"location":"Lab/4-Customizing-Tasks/","text":"Customizing Tasks with IBM watsonx Code Assistant for Ansible Lightspeed In the following module, you will begin experimentating with customized Ansible Playbooks and testing how changes to Ansible Task natural language descriptions impacts the recommended code produced by Generative AI. A sample Playbook is supplied for you below. Copy and paste the following code template into a New File... within your VS Code environment. CREATING NEW YAML FILES To create a new YAML Playbook within a VS Code environment: Copy the contents of the Playbook to clipboard using the button in the top-right corner of the lab guide code block. Return to your VS Code environment. In the top-left corner of the interface, with your Ansible Lightspeed folder selected, click the New File... button. Name the file to a description of your choosing, ending with .yml as the filetype. Set it to CustomPlaybook.yml , for example. Paste the clipboard contents into the YAML file and follow along with the suggestions below. CUSTOM PLAYBOOK #1 - Invoke 2 modules to automatically update 2 types of servers 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 # ANSIBLE PLAYBOOK \u2014 Invoke 2 modules to automatically update 2 types of servers. --- # Task 1 - name : Update web servers hosts : webservers become : true tasks : - name : Ensure apache is at the latest version ansible.builtin.yum : name : httpd state : latest - name : Write the apache config file ansible.builtin.template : src : /srv/httpd.j2 dest : /etc/httpd.config mode : \"0644\" # Task 2 - name : Update db servers hosts : databases become : true tasks : - name : Ensure postgresql is at the latest version ansible.builtin.yum : name : postgresql state : latest - name : Ensure that postgresql is started ansible.builtin.service : name : postgresql state : started Precision is key for disambiguation of natural language prompts. Custom Playbook #1 (above) contains 2 sets of tasks: Task 1 ( Lines 5-20 ) checks whether or not web server software is up to date and runs the update if necessary. Task 2 ( Lines 22-36 ) checks whether or not database server software is up to date and runs the update if necessary. Consider the following Task ( Line 16 ), which prompts Ansible to create (\"write\") a configuration file for an Apache webserver: - name : Write the apache config file Two tabs are presented below. The first AI-Generated Code tab shows the output from running Ansible Lightspeed's generative AI capabilities on an unmodified version of this Playbook. The second Solution Code tab shows the expected Task code that was written by a human programmer to perform the same task. In theory, the AI-generated code should be as good\u2014 or even superior to \u2014the manually-written solution code. Let's examine that theory in practice: AI-Generated Code Solution Code 1 2 3 4 - name : Write the apache config file ansible.builtin.copy : content : \"{{ _content_ }}\" dest : /etc/httpd/conf.d/000-default.conf 1 2 3 4 5 - name : Write the apache config file ansible.builtin.template : src : /srv/httpd.j2 dest : /etc/httpd.config mode : \"0644\" As you can see, the AI-generated code in the first tab misses the mark in a few areas. In fact, it appears to have misunderstood the task in quite a few ways. There is no corresponding value to _content_ that can be located within the Ansible Playbook, at least not any which you (the author) have defined ahead of time. Such a result is unexpected and does not match the intention of writing an Apache configuration file according to best practices. Similarly, the destination has been inferred differently and the access permissions that should have been applied to the config file (again - according to Red Hat best practices) are missing altogether. WHY THE UNEXPECTED RESULTS? Something has gone wrong \u2014 is Ansible Lightspeed at fault? The root cause of the error, in fact, is human . The precision with which the Playbook author describes the automation Task in natural language will determine the accuracy and effectiveness of Ansible Lightspeed's generated code suggestions. In general, the more ambiguous the Task description given, the greater the likelihood that Ansible Lightspeed will misinterpret the author's intent and suggest unwanted Ansible automation jobs. To help disambiguate our intention, Playbook authors must use more precise natural language terms and descriptions. Let's slightly modify the Task description. Try revising the Task -name: ... description to the following, hit Return , and accept the generated results with the TAB key: - name : Write the apache config file with mode 0644 Compare how the AI-generated code suggestions match (or don't) the expected code solution: AI-Generated Code Solution Code 1 2 3 4 5 - name : Write the apache config file with mode 0644 ansible.builtin.copy : dest : /etc/httpd/conf/httpd.conf content : \"Alias / /var/www/html/\\n\\n<Directory /var/www/html/\\\">\\n <Files>\\n\\\\ &2\\n &1\\n </Files>\\n </Directory>\\n</Dispatcher>\\n\" mode : '0644' 1 2 3 4 5 - name : Write the apache config file ansible.builtin.template : src : /srv/httpd.j2 dest : /etc/httpd.config mode : \"0644\" The output is closer to the expected on the latest iteration, but still out of alignment in some aspects. The AI-generated code suggestions now correctly include the 0644 read/write/execute permissions that were requested. However, an incorrect destination was suggested (instead of a source) and the content field is a mismatch to the request entirely. One other observation is that the suggested code is invoking the ansible.builtin.copy package, instead of the expected ansible.builtin.template package. What happens if we adjust the Task's natural language description to explicitly invoke the .template package? Adjust the Task description to the following and then re-generate the code block using Ansible Lightspeed: - name : Write the apache config file using mode 0644 from template Once again, compare the AI-generated code suggestions to the expected code solution: AI-Generated Code Solution Code 1 2 3 4 - name : Write the apache config file using mode 0644 from template ansible.builtin.copy : src : /home/ano-user/automation/ansible/templates/httpd.j2 dest : /etc/httpd/conf/httpd.conf 1 2 3 4 5 - name : Write the apache config file ansible.builtin.template : src : /srv/httpd.j2 dest : /etc/httpd.config mode : \"0644\" Annoyingly, the request to generate \" from template \" appears to have been misinterpreted once again. Looking at the syntax of the natural language description gives some clues as to why: Line 1 of AI-Generated Code , if you examine it the way a natural language processor would, is essentially a string of individual tokens. Every word, number, or character separated by a whitespace (a \"tokenizer\") is a \"token.\" In our example, mode and 0644 are separate tokens \u2014 and we expect that the AI mode's natural language capabilities will understand the implied link between these two. But we can make this linkage more explicit by being more exact with how we describe these two elements in the next iteration. Next time, we'll write them as a single token with a very explicit linkage by using mode='0644' and compare the resulting generated code. Line 2 of AI-Generated Code once again failed to invoke the expected ansible.builtin.template package. At this stage, you may speculate that the reason for this is the ambiguity created by the separate mode and 0644 tokens that were described previously. We will observe on the next generative iteration whether disambiguation of those two tokens helps clarify the meaning of the from template tokens. The mode: , src: , and dest: fields from Lines 3-5 of Solution Code are incorrect or missing. For a third time, let's adjust the natural language description of the Task to the following and then re-generate the code block using Ansible Lightspeed: - name : Write the apache config file using mode='0644' from template Once again, compare the AI-generated code suggestions to the expected code solution: AI-Generated Code Solution Code 1 2 3 4 5 6 7 - name : Write the apache config file using mode='0644' from template ansible.builtin.template : src : httpd.j2 dest : /etc/httpd/conf/httpd.conf owner : root group : root mode : '0644' 1 2 3 4 5 - name : Write the apache config file ansible.builtin.template : src : /srv/httpd.j2 dest : /etc/httpd.config mode : \"0644\" The resulting code suggestions from a simple tweak of mode 0644 to mode='0644' to disambiguate the purpose of the Task is far better than previous iterations. Not only was the mode: variable correctly set, but the generative AI code correctly picked up on the intention to invoke the Ansible builtin.template package. The iterative process we have gone through with this example can be viewed in two different ways. On the one hand, it shows the sensitivity of these generative AI models to even the most nuanced change in natural language prompts \u2014 for good or bad. Generative AI can produce tremendous work and that output is further guided along by best practices built-in from Red Hat and IBM. But in the end, the AI can only infer user intent from the natural language descriptions supplied to it. The more clearly you define your Task descriptions and intent, the more likely that Ansible Lightspeed will correctly generate code that mirrors that intent; conversely, the less precise your are, the more likely it will misinterpret and miss the mark. Precision is key to the disambiguation of natural language prompts. Human feedback and humans-in-the-loop are essential to these formative stages of Generative AI. As offerings like IBM watsonx Code Assistant for Red Hat Ansible Lightspeed achieve general availability (GA) status and exit the Tech Preview phase, the natural language processing capabilities of the service will continue to refine and improve. Additional packages, functions, and training data from Ansible Galaxy (as well as other sources) are continuously being added to the service's Foundation Models, which will in turn continually improve the AI-generated code recommendations made to users. Feedback can be directly supplied via the Ansible Lightspeed extension for VS Code and additional ways to support model training are documented online . In the following module, you will craft a fully-functional Ansible Playbook for the automated deployment of an Amazon EC2 instance and WordPress application \u2014 deployable from your local machine into a live AWS environment.","title":"Customizing Tasks"},{"location":"Lab/4-Customizing-Tasks/#customizing-tasks-with-ibm-watsonx-code-assistant-for-ansible-lightspeed","text":"In the following module, you will begin experimentating with customized Ansible Playbooks and testing how changes to Ansible Task natural language descriptions impacts the recommended code produced by Generative AI. A sample Playbook is supplied for you below. Copy and paste the following code template into a New File... within your VS Code environment. CREATING NEW YAML FILES To create a new YAML Playbook within a VS Code environment: Copy the contents of the Playbook to clipboard using the button in the top-right corner of the lab guide code block. Return to your VS Code environment. In the top-left corner of the interface, with your Ansible Lightspeed folder selected, click the New File... button. Name the file to a description of your choosing, ending with .yml as the filetype. Set it to CustomPlaybook.yml , for example. Paste the clipboard contents into the YAML file and follow along with the suggestions below. CUSTOM PLAYBOOK #1 - Invoke 2 modules to automatically update 2 types of servers 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 # ANSIBLE PLAYBOOK \u2014 Invoke 2 modules to automatically update 2 types of servers. --- # Task 1 - name : Update web servers hosts : webservers become : true tasks : - name : Ensure apache is at the latest version ansible.builtin.yum : name : httpd state : latest - name : Write the apache config file ansible.builtin.template : src : /srv/httpd.j2 dest : /etc/httpd.config mode : \"0644\" # Task 2 - name : Update db servers hosts : databases become : true tasks : - name : Ensure postgresql is at the latest version ansible.builtin.yum : name : postgresql state : latest - name : Ensure that postgresql is started ansible.builtin.service : name : postgresql state : started","title":"Customizing Tasks with IBM watsonx Code Assistant for Ansible Lightspeed"},{"location":"Lab/4-Customizing-Tasks/#_1","text":"","title":""},{"location":"Lab/4-Customizing-Tasks/#precision-is-key-for-disambiguation-of-natural-language-prompts","text":"Custom Playbook #1 (above) contains 2 sets of tasks: Task 1 ( Lines 5-20 ) checks whether or not web server software is up to date and runs the update if necessary. Task 2 ( Lines 22-36 ) checks whether or not database server software is up to date and runs the update if necessary. Consider the following Task ( Line 16 ), which prompts Ansible to create (\"write\") a configuration file for an Apache webserver: - name : Write the apache config file Two tabs are presented below. The first AI-Generated Code tab shows the output from running Ansible Lightspeed's generative AI capabilities on an unmodified version of this Playbook. The second Solution Code tab shows the expected Task code that was written by a human programmer to perform the same task. In theory, the AI-generated code should be as good\u2014 or even superior to \u2014the manually-written solution code. Let's examine that theory in practice: AI-Generated Code Solution Code 1 2 3 4 - name : Write the apache config file ansible.builtin.copy : content : \"{{ _content_ }}\" dest : /etc/httpd/conf.d/000-default.conf 1 2 3 4 5 - name : Write the apache config file ansible.builtin.template : src : /srv/httpd.j2 dest : /etc/httpd.config mode : \"0644\" As you can see, the AI-generated code in the first tab misses the mark in a few areas. In fact, it appears to have misunderstood the task in quite a few ways. There is no corresponding value to _content_ that can be located within the Ansible Playbook, at least not any which you (the author) have defined ahead of time. Such a result is unexpected and does not match the intention of writing an Apache configuration file according to best practices. Similarly, the destination has been inferred differently and the access permissions that should have been applied to the config file (again - according to Red Hat best practices) are missing altogether. WHY THE UNEXPECTED RESULTS? Something has gone wrong \u2014 is Ansible Lightspeed at fault? The root cause of the error, in fact, is human . The precision with which the Playbook author describes the automation Task in natural language will determine the accuracy and effectiveness of Ansible Lightspeed's generated code suggestions. In general, the more ambiguous the Task description given, the greater the likelihood that Ansible Lightspeed will misinterpret the author's intent and suggest unwanted Ansible automation jobs. To help disambiguate our intention, Playbook authors must use more precise natural language terms and descriptions. Let's slightly modify the Task description. Try revising the Task -name: ... description to the following, hit Return , and accept the generated results with the TAB key: - name : Write the apache config file with mode 0644 Compare how the AI-generated code suggestions match (or don't) the expected code solution: AI-Generated Code Solution Code 1 2 3 4 5 - name : Write the apache config file with mode 0644 ansible.builtin.copy : dest : /etc/httpd/conf/httpd.conf content : \"Alias / /var/www/html/\\n\\n<Directory /var/www/html/\\\">\\n <Files>\\n\\\\ &2\\n &1\\n </Files>\\n </Directory>\\n</Dispatcher>\\n\" mode : '0644' 1 2 3 4 5 - name : Write the apache config file ansible.builtin.template : src : /srv/httpd.j2 dest : /etc/httpd.config mode : \"0644\" The output is closer to the expected on the latest iteration, but still out of alignment in some aspects. The AI-generated code suggestions now correctly include the 0644 read/write/execute permissions that were requested. However, an incorrect destination was suggested (instead of a source) and the content field is a mismatch to the request entirely. One other observation is that the suggested code is invoking the ansible.builtin.copy package, instead of the expected ansible.builtin.template package. What happens if we adjust the Task's natural language description to explicitly invoke the .template package? Adjust the Task description to the following and then re-generate the code block using Ansible Lightspeed: - name : Write the apache config file using mode 0644 from template Once again, compare the AI-generated code suggestions to the expected code solution: AI-Generated Code Solution Code 1 2 3 4 - name : Write the apache config file using mode 0644 from template ansible.builtin.copy : src : /home/ano-user/automation/ansible/templates/httpd.j2 dest : /etc/httpd/conf/httpd.conf 1 2 3 4 5 - name : Write the apache config file ansible.builtin.template : src : /srv/httpd.j2 dest : /etc/httpd.config mode : \"0644\" Annoyingly, the request to generate \" from template \" appears to have been misinterpreted once again. Looking at the syntax of the natural language description gives some clues as to why: Line 1 of AI-Generated Code , if you examine it the way a natural language processor would, is essentially a string of individual tokens. Every word, number, or character separated by a whitespace (a \"tokenizer\") is a \"token.\" In our example, mode and 0644 are separate tokens \u2014 and we expect that the AI mode's natural language capabilities will understand the implied link between these two. But we can make this linkage more explicit by being more exact with how we describe these two elements in the next iteration. Next time, we'll write them as a single token with a very explicit linkage by using mode='0644' and compare the resulting generated code. Line 2 of AI-Generated Code once again failed to invoke the expected ansible.builtin.template package. At this stage, you may speculate that the reason for this is the ambiguity created by the separate mode and 0644 tokens that were described previously. We will observe on the next generative iteration whether disambiguation of those two tokens helps clarify the meaning of the from template tokens. The mode: , src: , and dest: fields from Lines 3-5 of Solution Code are incorrect or missing. For a third time, let's adjust the natural language description of the Task to the following and then re-generate the code block using Ansible Lightspeed: - name : Write the apache config file using mode='0644' from template Once again, compare the AI-generated code suggestions to the expected code solution: AI-Generated Code Solution Code 1 2 3 4 5 6 7 - name : Write the apache config file using mode='0644' from template ansible.builtin.template : src : httpd.j2 dest : /etc/httpd/conf/httpd.conf owner : root group : root mode : '0644' 1 2 3 4 5 - name : Write the apache config file ansible.builtin.template : src : /srv/httpd.j2 dest : /etc/httpd.config mode : \"0644\" The resulting code suggestions from a simple tweak of mode 0644 to mode='0644' to disambiguate the purpose of the Task is far better than previous iterations. Not only was the mode: variable correctly set, but the generative AI code correctly picked up on the intention to invoke the Ansible builtin.template package. The iterative process we have gone through with this example can be viewed in two different ways. On the one hand, it shows the sensitivity of these generative AI models to even the most nuanced change in natural language prompts \u2014 for good or bad. Generative AI can produce tremendous work and that output is further guided along by best practices built-in from Red Hat and IBM. But in the end, the AI can only infer user intent from the natural language descriptions supplied to it. The more clearly you define your Task descriptions and intent, the more likely that Ansible Lightspeed will correctly generate code that mirrors that intent; conversely, the less precise your are, the more likely it will misinterpret and miss the mark. Precision is key to the disambiguation of natural language prompts. Human feedback and humans-in-the-loop are essential to these formative stages of Generative AI. As offerings like IBM watsonx Code Assistant for Red Hat Ansible Lightspeed achieve general availability (GA) status and exit the Tech Preview phase, the natural language processing capabilities of the service will continue to refine and improve. Additional packages, functions, and training data from Ansible Galaxy (as well as other sources) are continuously being added to the service's Foundation Models, which will in turn continually improve the AI-generated code recommendations made to users. Feedback can be directly supplied via the Ansible Lightspeed extension for VS Code and additional ways to support model training are documented online . In the following module, you will craft a fully-functional Ansible Playbook for the automated deployment of an Amazon EC2 instance and WordPress application \u2014 deployable from your local machine into a live AWS environment.","title":"Precision is key for disambiguation of natural language prompts."},{"location":"Lab/5-Advanced-Topics-EC2-WordPress/","text":"Advanced : Deploying a live AWS EC2 instance and WordPress application via Ansible To conclude the Level 3 Technical Sales education on IBM watsonx Code Assistant for Red Hat Ansible Lightspeed , you will be provided with a complete set of instructions for deploying a LIVE Amazon Web Services (AWS) environment with Ansible automation, consisting of a WordPress web application running atop an Amazon EC2 VPC . The deployment of the environments will be conducted entirely using Red Hat Ansible automation, executed on your local machine, and deployed to AWS cloud. The generation of the Ansible Tasks and code required to automate these deployments will be created using the Generative AI capabilities of the Ansible Lightspeed extension for VS Code. COSTS Be aware that deploying a live Amazon EC2 instance on AWS does incur real-world charges which are the responsibility of the individual to pay for. If you wish to go ahead with deploying the live environment\u2014 which you are encouraged, but NOT REQUIRED, to complete \u2014you will need to do so on your personal AWS account, with any potential billings and charges incurred to your personal credit card. The billing associated with an Amazon EC2 t2.small instance and other services needed for the demo is minimal : an on-demand hourly rate of $0.023 USD at the time of publication. Running the fully-deployed WordPress and EC2 environments for 24 hours cost USD $2.03 in billing when testing for publication. Additional AWS pricing details and plans are available online. Ansible Playbooks have been prepared ahead of time in a public GitHub repository and are available for your use at the links below. Once the two YAML files are available on your local machine, open them with VS Code and follow along with the instructions below. TEMPLATE ( .yml ) : https://github.com/bienko/WCA-Lightspeed-L3/blob/main/TEMPLATE.yml The TEMPLATE.yml Playbook contains the skeleton of the application you will ultimately build. Playbook structure, key variables, Task descriptions, and comments are provided. Use the Generative AI capabilities of Ansible Lightspeed to fill out the details of the various Ansible Tasks, then compare the results with the SOLUTION.yml file below. SOLUTION ( .yml ) : https://github.com/bienko/WCA-Lightspeed-L3/blob/main/SOLUTION.yml The SOLUTION.yml Playbook contains the complete set of Ansible Playbook instructions needed to fully deploy a live EC2 VPC instance on AWS and host a WordPress application within that environment. You will need to replace certain variables (indicated by comments in the code) with details specific to your personal AWS account and environment. Afterwards, you can\u2014 and are encouraged to \u2014execute the Playbook with Ansible and deploy a live , at-cost instance to your personal AWS account. DOWNLOAD .yml FILES TO DESKTOP You can easily downlod the TEMPLATE and SOLUTION .yml files to your local machine. Navigate to the GitHub links provided (above) and click the Download raw file button. Use Ansible Lightspeed to generate code with the TEMPLATE Playbook , then compare against the SOLUTION Playbook to evaluate the results. In the steps ahead, you will use Ansible Lightspeed's AI-generated code suggestions to populate the contents of Tasks within the TEMPLATE.yml Playbook. There are 14 Tasks in total and we will examine them each in turn. For each Task, a tabbed code snippet is provided within this lab documentation to make it easy for you to toggle between the TEMPLATE (the Task prior to AI-generated code suggestions) and the proper SOLUTION (the Task as it should be written for a successful deployment to AWS). Compare the AI-generated code suggestions you receive in VS Code with the expected SOLUTION code. You will find that there are occassional discrepancies and variables that need to be adjusted. Generative AI can save us tremendous amounts of time and effort by automating the creation of powerful blocks of code\u2014 as you will observe in generating these tasks \u2014but it still requires a degree of human supervision and double-checking. However, the time saved with hands on keyboard is enormous and the potential for the future is boundless. VS CODE EXTENSION You may need to copy and paste the contents of the TEMPLATE.yml file into a New File... within the same Lightspeed project directory that was used for the prevous lab modules in order for the VS Code extension to engage. Open the TEMPLATE.yml Playbook in VS Code and ensure that the Ansible Lightspeed extension is active. Scroll down MODULE 1 (Line 4) and take note of the comments, as well as the <PLACEHOLDER> values. If you wish to fully deploy this environment to AWS, you will need to register for an AWS account, create an IAM (Identity Access Management) user, and associate an SSH key with the necessary permissions to access the account. These values will then be substituted in your code for the aws_access_key and aws_secret_key variables. Instructions on how to sign up for AWS and create those keys will be included at the end of this module, and you will be reminded at that time to update these variables. However, for now, let's focus on generating the Ansible Tasks. Continue scrolling down until you reach TASK 1 (Line 18) for the creation of a virtual private cloud (VPC) named 'wordpress'. Generate the Task code within VS Code and compare your results with the SOLUTION tab. TEMPLATE SOLUTION # TASK 1 # Creation of a virtual private cloud (VPC) named 'wordpress'. # Should have value 10.0.0.0/16 associated with cidr_block. - name : Create VPC named wordpress # TASK 1 # Creation of a virtual private cloud (VPC) named 'wordpress'. # Should have value 10.0.0.0/16 associated with cidr_block. - name : Create VPC named wordpress amazon.aws.ec2_vpc_net : name : wordpress cidr_block : 10.0.0.0/16 state : present register : wordpress_vpc TAGS One element of AI-generated Task code that you may find yourself frequently needing to update are tags and other naming conventions, such as the register: wordpress_vpc pair in TASK 1 . While the Ansible Lightspeed extension will remember the context of variables that are already named within the Playbook, it will struggle with how to name new variables \u2014 like wordpress_vpc . Take note, however, that as you generate code for the other Tasks in the Playbook that wordpress_vpc will be recalled and referenced. After validating the previous code block, continue scrolling down until you reach TASK 2 (Line 23) for the creation of a security group which allows network traffic over SSH and HTTP/s. Generate, evaluate, and refine the Task code as needed. TEMPLATE SOLUTION # TASK 2 # Creation of the security group which allows traffic over SSH and HTTP/s # TCP ports 80-80, 443-443, 22-22 - name : Create and register wordpress_vpc VPC security group allow SSH and HTTP # TASK 2 # Creation of the security group which allows traffic over SSH and HTTP/s # TCP ports 80-80, 443-443, 22-22 - name : Create and register wordpress_vpc VPC security group allow SSH and HTTP amazon.aws.ec2_security_group : name : wordpress description : Allow SSH and HTTP/HTTPS vpc_id : \"{ { wordpress_vpc.vpc.id } }\" # Ignore extra space between { { cbaracters. rules : - proto : tcp from_port : 80 to_port : 80 cidr_ip : 0.0.0.0/0 - proto : tcp from_port : 443 to_port : 443 cidr_ip : 0.0.0.0/0 - proto : tcp from_port : 22 to_port : 22 cidr_ip : 0.0.0.0/0 register : wordpress_sg Notice that the wordpress_vpc attribute which was registered in TASK 2 has been referenced in the creation of the vpc_id in TASK 3. Ignore the additional space between adjacent {``{ characters that are included in SOLUTION code tabs \u2014 these are included only to allow rendering of the code block in GitHub and are not intended as part of the finalized code. Continue scrolling down until you reach TASK 3 (Line 28) for the creation of an internet gateway for the wordpress VPC. Generate, evaluate, and refine the Task code as needed. TEMPLATE SOLUTION # TASK 3 # Creation of an internet gateway for the wordpress VPC - name : Create internet gateway for VPC wordpress_vpc # TASK 3 # Creation of an internet gateway for the wordpress VPC - name : Create internet gateway for VPC wordpress_vpc amazon.aws.ec2_vpc_igw : vpc_id : \"{ { wordpress_vpc.vpc.id } }\" state : present register : wordpress_igw Continue down to TASK 4 (Line 32) for the creation of an AWS network subnet for the WordPress VPC. TEMPLATE SOLUTION # TASK 4 # Creation of a network subnet for the wordpress VPC - name : Create subnet in wordpress_vpc # TASK 4 # Creation of a network subnet for the wordpress VPC - name : Create subnet in wordpress_vpc amazon.aws.ec2_vpc_subnet : state : present vpc_id : \"{ { wordpress_vpc.vpc.id } }\" cidr : 10.0.0.0/16 register : wordpress_subnet Continue down to TASK 5 (Line 36) for the creation of a routing table associated with wordpress VPC's subnet and internet gateway. TEMPLATE SOLUTION # TASK 5 # Creation of a routing table associated with wordpress VPC's subnet and internet gateway - name : Create route table for subnet and gateway wordpress_igw # TASK 5 # Creation of a routing table associated with wordpress VPC's subnet and internet gateway - name : Create route table for subnet and gateway wordpress_igw amazon.aws.ec2_vpc_route_table : state : present vpc_id : \"{ { wordpress_vpc.vpc.id } }\" tags : Name : sg_public Project : phoenix subnets : - \"{ { wordpress_subnet.subnet.id } }\" routes : - dest : 0.0.0.0/0 gateway_id : \"{ { wordpress_igw.gateway_id } }\" register : wordpress_route_table As you can observe, Ansible Lightspeed can be \"creative\" with its choice of tags and identifiers. You are welcome to adjust these to your liking, or even eliminate them from the Task code altogether. In the majority of cases these tags and identifiers are used for organization and tracking purposes, but not necessarily anything critical to the functioning of the Ansible Playbook or the infrastructure it is automating. Continue further down until you reach TASK 6 (Line 40), which is one of the more consequential steps in the Playbook as it involves the creation of the Amazon EC2 t2.small instance on AWS according to the settings defined in TASKS 1-5. TEMPLATE SOLUTION # TASK 6 # Creation of an EC2 t2.small instance with attributes defined in Tasks 1-5 # Amazon Machine Image (ami) image_id: ami-026ebd4cfe2c043b2 # Registered to Red Hat Enterprise Linux 9 (HVM, 64-bit x86) image # Replace `key_name:` value with your EC2 .pem keypair - DO NOT include .pem as part of filename # Use 'chmod 400' to change file permissions of .pem file before executing Playbook - name : Create t2.small instance named wordpress in wordpress_subnet assign public ip # TASK 6 # Creation of an EC2 t2.small instance with attributes defined in Tasks 1-5 # Amazon Machine Image (ami) image_id: ami-026ebd4cfe2c043b2 # Registered to Red Hat Enterprise Linux 9 (HVM, 64-bit x86) image # Replace `key_name:` value with your EC2 .pem keypair - DO NOT include .pem as part of filename # Use 'chmod 400' to change file permissions of .pem file before executing Playbook - name : Create t2.small instance named wordpress in wordpress_subnet assign public ip amazon.aws.ec2_instance : name : wordpress image_id : \"ami-026ebd4cfe2c043b2\" instance_type : t2.small vpc_subnet_id : \"{ { wordpress_subnet.subnet.id } }\" security_groups : \"{ { wordpress_sg.group_id } }\" network : assign_public_ip : true key_name : \"bienko-key\" state : running register : wordpress_server Note that the image_id and ami values correspond to a specific Amazon Machine Image (ami) for Red Hat Enterprise Linux 9. Hundreds of alternative operating system images are available to select from on AWS, so you may modify this if you so choose; however, for the purposes of deploying WordPress it will make no meaningful difference. The pair key_name: \"bienko-key\" relates to an EC2 instance key (SSH) that you will need to create before attempting to deploy an EC2 instance via Ansible. Instructions for how to create that key will be given at the end of this module for those who wish to deploy a live environment. Continue down to TASK 7 (Line 48). You will notice that in both the TEMPLATE and SOLUTION versions of the Playbook that this Task is fully defined already. Despite repeated attempts at describing the Task to be generated, Ansible Lightspeed in its pre-GA Technical Preview form was unable to generate all of the actions needed to carry out this task. Over time the service will doubtlessly be able to handle this particular task \u2014 but for now, leave this as a hard-coded element within your Playbook and do not attempt to recreate the task with code generation. TEMPLATE SOLUTION # TASK 7 # This section has been hard-coded ahead of time. # DO NOT regenerate using AI-suggested code. # Replace `ansible_ssh_private_key_file` value with path on local machine to SSH key \u2014 INCLUDE .pem as part of filename # Use 'chmod 400' to change file permissions of .pem file before executing Playbook - name : Add host to inventory using tunnel using wordpress_instance public ip and ansible user ec2-user ansible.builtin.add_host : name : wordpress ansible_host : \"{ { wordpress_server.instances[0].public_ip_address } }\" ansible_user : ec2-user ansible_ssh_private_key_file : \"bienko-key.pem\" # TASK 7 # This section has been hard-coded ahead of time. # DO NOT regenerate using AI-suggested code. # Replace `ansible_ssh_private_key_file` value with path on local machine to SSH key \u2014 INCLUDE .pem as part of filename # Use 'chmod 400' to change file permissions of .pem file before executing Playbook - name : Add host to inventory using tunnel using wordpress_instance public ip and ansible user ec2-user ansible.builtin.add_host : name : wordpress ansible_host : \"{ { wordpress_server.instances[0].public_ip_address } }\" ansible_user : ec2-user ansible_ssh_private_key_file : \"bienko-key.pem\" PLAYBOOK MODIFICATIONS REQUIRED Although TASK 7 does not require Ansible Lightspeed to generate any code suggestions, it does require the user to modify the value of the ansible_ssh_private_key_file attribute. Set this attribute to the directory path where the private SSH key ( .pem file) is located on your local machine. Be sure to include the .pem filetype as part of the value and also ensure you have changed the permissions on the file (using Terminal and executing the chmod 400 bienko-key.pem instruction) before attempting to run the Playbook. Scrolling further down the Playbook you will \"enter\" MODULE B (Line 60), made up Ansible Tasks concerned with installing and configuring WordPress on the newly-provisioned AWS EC2 (VPC) instance. Locate TASK 8 (Line 67) which waits for a connection to be established to the EC2 instance before advancing the sequence of automation tasks. TEMPLATE SOLUTION # TASK 8 # Wait for a connection to be established to the EC2 instance. - name : Wait for connection # TASK 8 # Wait for a connection to be established to the EC2 instance. - name : Wait for connection ansible.builtin.wait_for_connection : delay : 10 timeout : 30 Next, continue further down the Playbook and locate TASK 9 (Line 71) which commences installation of the necessary drivers and services on Amazon EC2 once a connection to the instance has been established. TEMPLATE SOLUTION # TASK 9 # After connecting, begin installation of necessary drivers and services. - name : Install httpd, php, php-mysqli, and mariadb-server # TASK 9 # After connecting, begin installation of necessary drivers and services. - name : Install httpd, php, php-mysqli, and mariadb-server ansible.builtin.package : name : - httpd - php - php-mysqlnd - mariadb-server state : present Scroll down further until you locate TASK 10 (Line 75) which is responsible for downloading and decompressing (unarchiving) WordPress installation contents onto the EC2 instance. TEMPLATE SOLUTION # TASK 10 # Download and decompress (unarchive) WordPress contents on EC2 instance. - name : Download and unarchive wordpress # TASK 10 # Download and decompress (unarchive) WordPress contents on EC2 instance. - name : Download and unarchive wordpress ansible.builtin.unarchive : src : https://wordpress.org/latest.tar.gz dest : /var/www/html remote_src : true creates : /var/www/html/wordpress Afterwards, locate TASK 11 (Line 79) which sets the ownership attributes for the WordPress environment on Amazon EC2 and prepares it for hosting via Apache webserver. TEMPLATE SOLUTION # TASK 11 # Set owner attributes for WordPress environment. - name : Change owner of /var/www/html/wordpress to apache:apache # TASK 11 # Set owner attributes for WordPress environment. - name : Change owner of /var/www/html/wordpress to apache:apache ansible.builtin.file : path : /var/www/html owner : apache group : apache recurse : true Further down the Playbook, locate TASK 12 (Line 83) which deploys the services installed in TASK 9. TEMPLATE SOLUTION # TASK 12 # Deploy services installed in Task 9. - name : Start and enable httpd, php-fpm and mariadb services # TASK 12 # Deploy services installed in Task 9. - name : Start and enable httpd, php-fpm and mariadb services ansible.builtin.service : name : \"{ { item } }\" state : started enabled : true loop : - httpd - php-fpm - mariadb MODULE C (Line 87) of the Playbook covers the final set of operations. It is responsible for ensuring that WordPress is deployed on the newly-provisioned AWS EC2 (VPC) instance and that the WordPress web page is accessible to the user. As you did previously in Step 2, you will need to replace the <PLACEHOLDER> values and region details on Lines 96-98 if you want to fully deploy this application into a live AWS environment. Locate TASK 13 (Line 101) which is responsible for gathering facts about AWS EC2 (VPC) instance and the deployed WordPress application that is running atop of it. TEMPLATE SOLUTION # TASK 13 # Gather facts about AWS EC2 (VPC) instance and deployed WordPress application. - name : Gather ec2 instance info for tag name wordpress # TASK 13 # Gather facts about AWS EC2 (VPC) instance and deployed WordPress application. - name : Gather ec2 instance info for tag name wordpress amazon.aws.ec2_instance_info : filters : tag:Name : wordpress instance-state-name : running register : ec2_facts Finally, you have arrived at the final step in the Playbook configuration: TASK 14 (Line 105), which is responsible for hosting the WordPress web app and making it accessible to users. TEMPLATE SOLUTION # TASK 14 # Host the WordPress web application and make accessible to user. - name : Debug ec2_facts public dns name # TASK 14 # Host the WordPress web application and make accessible to user. - name : Debug ec2_facts public dns name ansible.builtin.debug : msg : \"{ { ec2_facts.instances[0].public_dns_name } }/wordpress/readme.html\" Congratulations on making it this far! At this stage, your Playbook is ready for execution. However, there are still some preparation that you need to do before this Playbook can be used to automate deployment of the WordPress application into a live Amazon EC2 environment. If you wish to go ahead with the deployment ( RECOMMENDED ) on your personal AWS account, follow along with lab guide steps. Otherwise, you are welcome to conclude the hands-on component here and follow the Level 3 accreditation steps (depending on your role). LEVEL 3 ACCREDITATION IBMers should take the time now to prepare for and record their Stand & Deliver presentations for Level 3 accreditation. Be sure to follow the evaluation criteria that is outlined in this documentation. Business Partners should follow the learning plan links on IBM Training to complete a multiple-choice examination for Level 3 accreditation. To deploy a live Amazon EC2 instance and WordPress application on AWS, follow along with the steps below. In order to execute the Ansible Playbook on your local machine, you will need to install Ansible locally. Red Hat provides extensive online documentation for how to go about installing Ansible. The authors of your lab guide recommend doing so by executing the following instructions in a Terminal window (macOS), or equivalent steps using PowerShell (Windows): brew install ansible MISSING HOMEBREW? If you do not have the Homebrew package manager (\"brew\") installed in a macOS environment, execute the following instruction inside a Terminal console: /bin/bash -c \"$(curl -fsSL https://raw.githubusercontent.com/Homebrew/install/HEAD/install.sh)\" Wait for the installation to conclude and then retry the instructions from Step 18. Follow the prompts until you receive confirmation that Ansible is installed and available locally. If you have not registered for an AWS account previously, you need to do so now before advancing. You will need to supply a personal credit card for billing expenses. If you have an existing Amazon account, your AWS account can be linked to that profile if you so choose. AWS Registration : https://aws.amazon.com/resources/create-account/ With a registered AWS account, you next need to navigate from the AWS dashboard into the Identity and Access Management (IAM) tool. You can search for this using the Search bar at the top of the screen and entering IAM . Once inside the IAM tool, look along the left-side of the interface and drill down into Users . Click the Create User orange button located in the top-right corner of the interface. Within the Create User panel, specify your user details and permissions. Set Username to a name of your choosing. Click Next to advance the configuration tool. Under Set Permissions > Permission Options , select the Add user to group tile. Click the Set permissions boundary - optional tile to expand additional permission options. Toggle the checkmark next to the Use a permissions boundary to control the maximum permissions option. Under Permissions Policies , search the table for the AdministratorAccess policy and enable that policy. You may receive warnings against doing so \u2014 ignore those for now. Continue following the prompts until the User has been created. Once the User has been created, your web browser will reopen the User panel of the IAM tool. Here you can see various details about the User, including their Security Credentials and any keys associated with the User. This section will be empty given that you have only just now created the User. Drill down into the Access Keys category and click the Create Access Key button located below the (empty) table. A secret access key will be created and the web browser will reload to show you details about that key. RECORD THIS INFORMATION to a notepad. Details about the secret access key can only be viewed or downloaded at the time the key is created (now). It cannot be recovered afterwards. However, if you lose your key details, all is not lost \u2014 you can always create a new secret access key at a later time. Record the Access Key , which will be used to replace the <PLACEHOLDER> value assigned to aws_access_key in Step 2 and Step 15 of this lab guide. Record the Secret Access Key , which will replace the <PLACEHOLDER> value assigned to aws_secret_key in Step 2 and Step 15 of this lab guide. Take note at this time as well about the Region in which your AWS account is located. You can easily look up this information by examining the URL in your web browser address bar, as shown below ( us-east-1 ). RECORD the name of the region, as this will replace the region value assigned to the Playbook. PLAYBOOK MODIFICATIONS REQUIRED Replace the <PLACEHOLDER> values for variables aws_access_key and aws_secret_key with the Access Key and Secret Access Key , respectively. Lines 13, 14, 96, and 97 of the TEMPLATE.yml Playbook Lines 13, 14, 179, and 180 of the SOLUTION.yml Playbook Replace the value for variable region with the region assigned to your unique AWS account. Lines 15 and 98 of the TEMPLATE.yml Playbook Lines 15 and 181 of the SOLUTION.yml Playbook Next, you'll need to create an SSH Key Pair with authorization to interact with (and ultimately deploy) Amazon EC2 instances. Return to the search bar at the top of the AWS interface and enter EC2 . Drill down into the Amazon EC2 service page from the results. From the left-hand navigation bar, drill down into the Network & Security > Key Pairs tab. Click the orange Create key pair button in the top-right of the page. A configuration tool will ask for additional information about the Key Pair: Name can be set to a value of your choosing Key pair type set to RSA Private key file format set to .pem When satisfied, click the orange Create key pair button. The web browser will redirect to a page where you can view details about the newly-created Key Pair for EC2. Download the .pem file to your local device, preferably to the same directory that your TEMPLATE.yml and SOLUTION.yml Playbooks are located within. PLAYBOOK MODIFICATIONS REQUIRED The value of ansible_ssh_private_key_file must be updated within your Playbooks to account for the full path to the .pem file on your local machine. If you save the Key Pair file to the same directory that your Ansible Playbooks are located within, you do not need to qualify the value with anything more than the name of the file ( bienko-key.pem ). If it is saved in a different directory, you will need to spell out the full path + file name. Update the value of ansible_ssh_private_key_file in the following locations: Line 58 of the TEMPLATE.yml Playbook Line 113 of the SOLUTION.yml Playbook It is necessary to adjust the permissions assigned to the Key Pair file (on your local machine) before attempting to connect via Ansible to AWS. Open a Terminal console on your local machine and navigate ( cd ) to the directory in which the Key Pair file is saved. Execute the following to adjust the permissions assigned to the .pem file: chmod 400 filename.pem Executing the Ansible Playbook At last, you are ready to execute the Playbook and use Ansible automation to deploy both an Amazon EC2 instance and a WordPress web application. With the Terminal console, navigate to the directory ( cd ) where both the Ansible Playbook and your KeyPair.pem file are located. You may use either the TEMPLATE.yml Playbook that you customized or the SOLUTION.yml Playbook for executing the Ansible automation tasks. Regardless of the Playbook being used, you must modify the Playbook with the necessary AWS security and account credentials information. When ready, execute the following instruction with the Terminal console: ansible-playbook TEMPLATE.yml Monitor the console's output as the Ansible Playbook iterates across each of the Tasks customized earlier. A fantastic feature of Ansible's automation is that if any of the Tasks should fail, the steps involved in that Task can be re-tried in subsequent runs; likewise, Tasks which executed successfully won't be repeated, but are validated and skipped instead. If you encounter errors during the litany of automation tasks, return to the Playbook and attempt to debug the issue. Re-issue the instruction in Step 34 to console to attempt the Ansible Playbook execution again. Continue iterating in this manner until all 14 Tasks have been successfully executed. After successfully deploying the Amazon EC2 environment and instantiating a WordPress application, the console will return a URL to the Terminal's output as part of Task 14's [debug] instruction. Copy the URL to clipboard and then paste it into your web browser to access the WordPress application. If your web browser loads the quick-start page for WordPress, you have successfully deployed the application and its supporting EC2 environment \u2014 entirely using Generative AI and Ansible automation. Well done! Cleaning up and conclusion After you have recorded your Stand & Deliver presentations (IBM technical sellers only) and are ready to retire your environment, you will need to return to the AWS Dashboard to terminate the EC2 instance and hosted WordPress application. COSTS It is essential that you terminate and deprovision the EC2 instance at the conclusion of the hands on lab. Otherwise, your personal AWS account will continue to be billed for as long as the resources are provisioned. You can monitor your Amazon EC2 instance from the EC2 dashboard. At the top of the page, locate the Resources table and drill down into the Instances (running) tab. Details about your EC2 environment are summarized within the Instances table. Click the name of your EC2's Instance ID to expose additional details and management options. In the top-right corner of the interface, click the Instance state button and select Terminate instance from the drop-down menu. Confirm the deprovisioning request by clicking the orange Terminate button. All storage associated with the EC2 instance will automatically be deleted. Terminating an instance cannot be undone once underway. It is recommended that you delete all of the Security Groups (3 total) and Key Pairs (1 total) associated with the EC2 instance. To do so, return to the EC2 Dashboard and follow a similar procedure to Steps 38-41. Search for IAM in the AWS taskbar to return to the Identity Access Management panel. If you wish to further secure your AWS account, delete all unwanted users or consider reducing the user's privilege from AdministratorAccess to a more restrictive class. That concludes the hands-on components to this Level 3 course, but your learning and experimentation doesn't need to end here. Continue to experiment with generating Tasks for Ansible Playbooks. If you have worked extensively with Ansible previously, try recreating Tasks you've written previously from old Playbooks using generative AI \u2014 just be careful not to use confidential or sensitive information as part of those tests. See if you can spot the differences or improvements made from the AI-generated code recommendations. Feel free to reach out to the authors of this coursework if you have suggestions for Tasks or code generation techniques that you'd like to see included in future iterations of this hands-on training.","title":"Deploying an AWS EC2 Instance and WordPress Application"},{"location":"Lab/5-Advanced-Topics-EC2-WordPress/#advanced-deploying-a-live-aws-ec2-instance-and-wordpress-application-via-ansible","text":"To conclude the Level 3 Technical Sales education on IBM watsonx Code Assistant for Red Hat Ansible Lightspeed , you will be provided with a complete set of instructions for deploying a LIVE Amazon Web Services (AWS) environment with Ansible automation, consisting of a WordPress web application running atop an Amazon EC2 VPC . The deployment of the environments will be conducted entirely using Red Hat Ansible automation, executed on your local machine, and deployed to AWS cloud. The generation of the Ansible Tasks and code required to automate these deployments will be created using the Generative AI capabilities of the Ansible Lightspeed extension for VS Code. COSTS Be aware that deploying a live Amazon EC2 instance on AWS does incur real-world charges which are the responsibility of the individual to pay for. If you wish to go ahead with deploying the live environment\u2014 which you are encouraged, but NOT REQUIRED, to complete \u2014you will need to do so on your personal AWS account, with any potential billings and charges incurred to your personal credit card. The billing associated with an Amazon EC2 t2.small instance and other services needed for the demo is minimal : an on-demand hourly rate of $0.023 USD at the time of publication. Running the fully-deployed WordPress and EC2 environments for 24 hours cost USD $2.03 in billing when testing for publication. Additional AWS pricing details and plans are available online. Ansible Playbooks have been prepared ahead of time in a public GitHub repository and are available for your use at the links below. Once the two YAML files are available on your local machine, open them with VS Code and follow along with the instructions below. TEMPLATE ( .yml ) : https://github.com/bienko/WCA-Lightspeed-L3/blob/main/TEMPLATE.yml The TEMPLATE.yml Playbook contains the skeleton of the application you will ultimately build. Playbook structure, key variables, Task descriptions, and comments are provided. Use the Generative AI capabilities of Ansible Lightspeed to fill out the details of the various Ansible Tasks, then compare the results with the SOLUTION.yml file below. SOLUTION ( .yml ) : https://github.com/bienko/WCA-Lightspeed-L3/blob/main/SOLUTION.yml The SOLUTION.yml Playbook contains the complete set of Ansible Playbook instructions needed to fully deploy a live EC2 VPC instance on AWS and host a WordPress application within that environment. You will need to replace certain variables (indicated by comments in the code) with details specific to your personal AWS account and environment. Afterwards, you can\u2014 and are encouraged to \u2014execute the Playbook with Ansible and deploy a live , at-cost instance to your personal AWS account. DOWNLOAD .yml FILES TO DESKTOP You can easily downlod the TEMPLATE and SOLUTION .yml files to your local machine. Navigate to the GitHub links provided (above) and click the Download raw file button.","title":"Advanced: Deploying a live AWS EC2 instance and WordPress application via Ansible"},{"location":"Lab/5-Advanced-Topics-EC2-WordPress/#_1","text":"","title":""},{"location":"Lab/5-Advanced-Topics-EC2-WordPress/#use-ansible-lightspeed-to-generate-code-with-the-template-playbook-then-compare-against-the-solution-playbook-to-evaluate-the-results","text":"In the steps ahead, you will use Ansible Lightspeed's AI-generated code suggestions to populate the contents of Tasks within the TEMPLATE.yml Playbook. There are 14 Tasks in total and we will examine them each in turn. For each Task, a tabbed code snippet is provided within this lab documentation to make it easy for you to toggle between the TEMPLATE (the Task prior to AI-generated code suggestions) and the proper SOLUTION (the Task as it should be written for a successful deployment to AWS). Compare the AI-generated code suggestions you receive in VS Code with the expected SOLUTION code. You will find that there are occassional discrepancies and variables that need to be adjusted. Generative AI can save us tremendous amounts of time and effort by automating the creation of powerful blocks of code\u2014 as you will observe in generating these tasks \u2014but it still requires a degree of human supervision and double-checking. However, the time saved with hands on keyboard is enormous and the potential for the future is boundless. VS CODE EXTENSION You may need to copy and paste the contents of the TEMPLATE.yml file into a New File... within the same Lightspeed project directory that was used for the prevous lab modules in order for the VS Code extension to engage. Open the TEMPLATE.yml Playbook in VS Code and ensure that the Ansible Lightspeed extension is active. Scroll down MODULE 1 (Line 4) and take note of the comments, as well as the <PLACEHOLDER> values. If you wish to fully deploy this environment to AWS, you will need to register for an AWS account, create an IAM (Identity Access Management) user, and associate an SSH key with the necessary permissions to access the account. These values will then be substituted in your code for the aws_access_key and aws_secret_key variables. Instructions on how to sign up for AWS and create those keys will be included at the end of this module, and you will be reminded at that time to update these variables. However, for now, let's focus on generating the Ansible Tasks. Continue scrolling down until you reach TASK 1 (Line 18) for the creation of a virtual private cloud (VPC) named 'wordpress'. Generate the Task code within VS Code and compare your results with the SOLUTION tab. TEMPLATE SOLUTION # TASK 1 # Creation of a virtual private cloud (VPC) named 'wordpress'. # Should have value 10.0.0.0/16 associated with cidr_block. - name : Create VPC named wordpress # TASK 1 # Creation of a virtual private cloud (VPC) named 'wordpress'. # Should have value 10.0.0.0/16 associated with cidr_block. - name : Create VPC named wordpress amazon.aws.ec2_vpc_net : name : wordpress cidr_block : 10.0.0.0/16 state : present register : wordpress_vpc TAGS One element of AI-generated Task code that you may find yourself frequently needing to update are tags and other naming conventions, such as the register: wordpress_vpc pair in TASK 1 . While the Ansible Lightspeed extension will remember the context of variables that are already named within the Playbook, it will struggle with how to name new variables \u2014 like wordpress_vpc . Take note, however, that as you generate code for the other Tasks in the Playbook that wordpress_vpc will be recalled and referenced. After validating the previous code block, continue scrolling down until you reach TASK 2 (Line 23) for the creation of a security group which allows network traffic over SSH and HTTP/s. Generate, evaluate, and refine the Task code as needed. TEMPLATE SOLUTION # TASK 2 # Creation of the security group which allows traffic over SSH and HTTP/s # TCP ports 80-80, 443-443, 22-22 - name : Create and register wordpress_vpc VPC security group allow SSH and HTTP # TASK 2 # Creation of the security group which allows traffic over SSH and HTTP/s # TCP ports 80-80, 443-443, 22-22 - name : Create and register wordpress_vpc VPC security group allow SSH and HTTP amazon.aws.ec2_security_group : name : wordpress description : Allow SSH and HTTP/HTTPS vpc_id : \"{ { wordpress_vpc.vpc.id } }\" # Ignore extra space between { { cbaracters. rules : - proto : tcp from_port : 80 to_port : 80 cidr_ip : 0.0.0.0/0 - proto : tcp from_port : 443 to_port : 443 cidr_ip : 0.0.0.0/0 - proto : tcp from_port : 22 to_port : 22 cidr_ip : 0.0.0.0/0 register : wordpress_sg Notice that the wordpress_vpc attribute which was registered in TASK 2 has been referenced in the creation of the vpc_id in TASK 3. Ignore the additional space between adjacent {``{ characters that are included in SOLUTION code tabs \u2014 these are included only to allow rendering of the code block in GitHub and are not intended as part of the finalized code. Continue scrolling down until you reach TASK 3 (Line 28) for the creation of an internet gateway for the wordpress VPC. Generate, evaluate, and refine the Task code as needed. TEMPLATE SOLUTION # TASK 3 # Creation of an internet gateway for the wordpress VPC - name : Create internet gateway for VPC wordpress_vpc # TASK 3 # Creation of an internet gateway for the wordpress VPC - name : Create internet gateway for VPC wordpress_vpc amazon.aws.ec2_vpc_igw : vpc_id : \"{ { wordpress_vpc.vpc.id } }\" state : present register : wordpress_igw Continue down to TASK 4 (Line 32) for the creation of an AWS network subnet for the WordPress VPC. TEMPLATE SOLUTION # TASK 4 # Creation of a network subnet for the wordpress VPC - name : Create subnet in wordpress_vpc # TASK 4 # Creation of a network subnet for the wordpress VPC - name : Create subnet in wordpress_vpc amazon.aws.ec2_vpc_subnet : state : present vpc_id : \"{ { wordpress_vpc.vpc.id } }\" cidr : 10.0.0.0/16 register : wordpress_subnet Continue down to TASK 5 (Line 36) for the creation of a routing table associated with wordpress VPC's subnet and internet gateway. TEMPLATE SOLUTION # TASK 5 # Creation of a routing table associated with wordpress VPC's subnet and internet gateway - name : Create route table for subnet and gateway wordpress_igw # TASK 5 # Creation of a routing table associated with wordpress VPC's subnet and internet gateway - name : Create route table for subnet and gateway wordpress_igw amazon.aws.ec2_vpc_route_table : state : present vpc_id : \"{ { wordpress_vpc.vpc.id } }\" tags : Name : sg_public Project : phoenix subnets : - \"{ { wordpress_subnet.subnet.id } }\" routes : - dest : 0.0.0.0/0 gateway_id : \"{ { wordpress_igw.gateway_id } }\" register : wordpress_route_table As you can observe, Ansible Lightspeed can be \"creative\" with its choice of tags and identifiers. You are welcome to adjust these to your liking, or even eliminate them from the Task code altogether. In the majority of cases these tags and identifiers are used for organization and tracking purposes, but not necessarily anything critical to the functioning of the Ansible Playbook or the infrastructure it is automating. Continue further down until you reach TASK 6 (Line 40), which is one of the more consequential steps in the Playbook as it involves the creation of the Amazon EC2 t2.small instance on AWS according to the settings defined in TASKS 1-5. TEMPLATE SOLUTION # TASK 6 # Creation of an EC2 t2.small instance with attributes defined in Tasks 1-5 # Amazon Machine Image (ami) image_id: ami-026ebd4cfe2c043b2 # Registered to Red Hat Enterprise Linux 9 (HVM, 64-bit x86) image # Replace `key_name:` value with your EC2 .pem keypair - DO NOT include .pem as part of filename # Use 'chmod 400' to change file permissions of .pem file before executing Playbook - name : Create t2.small instance named wordpress in wordpress_subnet assign public ip # TASK 6 # Creation of an EC2 t2.small instance with attributes defined in Tasks 1-5 # Amazon Machine Image (ami) image_id: ami-026ebd4cfe2c043b2 # Registered to Red Hat Enterprise Linux 9 (HVM, 64-bit x86) image # Replace `key_name:` value with your EC2 .pem keypair - DO NOT include .pem as part of filename # Use 'chmod 400' to change file permissions of .pem file before executing Playbook - name : Create t2.small instance named wordpress in wordpress_subnet assign public ip amazon.aws.ec2_instance : name : wordpress image_id : \"ami-026ebd4cfe2c043b2\" instance_type : t2.small vpc_subnet_id : \"{ { wordpress_subnet.subnet.id } }\" security_groups : \"{ { wordpress_sg.group_id } }\" network : assign_public_ip : true key_name : \"bienko-key\" state : running register : wordpress_server Note that the image_id and ami values correspond to a specific Amazon Machine Image (ami) for Red Hat Enterprise Linux 9. Hundreds of alternative operating system images are available to select from on AWS, so you may modify this if you so choose; however, for the purposes of deploying WordPress it will make no meaningful difference. The pair key_name: \"bienko-key\" relates to an EC2 instance key (SSH) that you will need to create before attempting to deploy an EC2 instance via Ansible. Instructions for how to create that key will be given at the end of this module for those who wish to deploy a live environment. Continue down to TASK 7 (Line 48). You will notice that in both the TEMPLATE and SOLUTION versions of the Playbook that this Task is fully defined already. Despite repeated attempts at describing the Task to be generated, Ansible Lightspeed in its pre-GA Technical Preview form was unable to generate all of the actions needed to carry out this task. Over time the service will doubtlessly be able to handle this particular task \u2014 but for now, leave this as a hard-coded element within your Playbook and do not attempt to recreate the task with code generation. TEMPLATE SOLUTION # TASK 7 # This section has been hard-coded ahead of time. # DO NOT regenerate using AI-suggested code. # Replace `ansible_ssh_private_key_file` value with path on local machine to SSH key \u2014 INCLUDE .pem as part of filename # Use 'chmod 400' to change file permissions of .pem file before executing Playbook - name : Add host to inventory using tunnel using wordpress_instance public ip and ansible user ec2-user ansible.builtin.add_host : name : wordpress ansible_host : \"{ { wordpress_server.instances[0].public_ip_address } }\" ansible_user : ec2-user ansible_ssh_private_key_file : \"bienko-key.pem\" # TASK 7 # This section has been hard-coded ahead of time. # DO NOT regenerate using AI-suggested code. # Replace `ansible_ssh_private_key_file` value with path on local machine to SSH key \u2014 INCLUDE .pem as part of filename # Use 'chmod 400' to change file permissions of .pem file before executing Playbook - name : Add host to inventory using tunnel using wordpress_instance public ip and ansible user ec2-user ansible.builtin.add_host : name : wordpress ansible_host : \"{ { wordpress_server.instances[0].public_ip_address } }\" ansible_user : ec2-user ansible_ssh_private_key_file : \"bienko-key.pem\" PLAYBOOK MODIFICATIONS REQUIRED Although TASK 7 does not require Ansible Lightspeed to generate any code suggestions, it does require the user to modify the value of the ansible_ssh_private_key_file attribute. Set this attribute to the directory path where the private SSH key ( .pem file) is located on your local machine. Be sure to include the .pem filetype as part of the value and also ensure you have changed the permissions on the file (using Terminal and executing the chmod 400 bienko-key.pem instruction) before attempting to run the Playbook. Scrolling further down the Playbook you will \"enter\" MODULE B (Line 60), made up Ansible Tasks concerned with installing and configuring WordPress on the newly-provisioned AWS EC2 (VPC) instance. Locate TASK 8 (Line 67) which waits for a connection to be established to the EC2 instance before advancing the sequence of automation tasks. TEMPLATE SOLUTION # TASK 8 # Wait for a connection to be established to the EC2 instance. - name : Wait for connection # TASK 8 # Wait for a connection to be established to the EC2 instance. - name : Wait for connection ansible.builtin.wait_for_connection : delay : 10 timeout : 30 Next, continue further down the Playbook and locate TASK 9 (Line 71) which commences installation of the necessary drivers and services on Amazon EC2 once a connection to the instance has been established. TEMPLATE SOLUTION # TASK 9 # After connecting, begin installation of necessary drivers and services. - name : Install httpd, php, php-mysqli, and mariadb-server # TASK 9 # After connecting, begin installation of necessary drivers and services. - name : Install httpd, php, php-mysqli, and mariadb-server ansible.builtin.package : name : - httpd - php - php-mysqlnd - mariadb-server state : present Scroll down further until you locate TASK 10 (Line 75) which is responsible for downloading and decompressing (unarchiving) WordPress installation contents onto the EC2 instance. TEMPLATE SOLUTION # TASK 10 # Download and decompress (unarchive) WordPress contents on EC2 instance. - name : Download and unarchive wordpress # TASK 10 # Download and decompress (unarchive) WordPress contents on EC2 instance. - name : Download and unarchive wordpress ansible.builtin.unarchive : src : https://wordpress.org/latest.tar.gz dest : /var/www/html remote_src : true creates : /var/www/html/wordpress Afterwards, locate TASK 11 (Line 79) which sets the ownership attributes for the WordPress environment on Amazon EC2 and prepares it for hosting via Apache webserver. TEMPLATE SOLUTION # TASK 11 # Set owner attributes for WordPress environment. - name : Change owner of /var/www/html/wordpress to apache:apache # TASK 11 # Set owner attributes for WordPress environment. - name : Change owner of /var/www/html/wordpress to apache:apache ansible.builtin.file : path : /var/www/html owner : apache group : apache recurse : true Further down the Playbook, locate TASK 12 (Line 83) which deploys the services installed in TASK 9. TEMPLATE SOLUTION # TASK 12 # Deploy services installed in Task 9. - name : Start and enable httpd, php-fpm and mariadb services # TASK 12 # Deploy services installed in Task 9. - name : Start and enable httpd, php-fpm and mariadb services ansible.builtin.service : name : \"{ { item } }\" state : started enabled : true loop : - httpd - php-fpm - mariadb MODULE C (Line 87) of the Playbook covers the final set of operations. It is responsible for ensuring that WordPress is deployed on the newly-provisioned AWS EC2 (VPC) instance and that the WordPress web page is accessible to the user. As you did previously in Step 2, you will need to replace the <PLACEHOLDER> values and region details on Lines 96-98 if you want to fully deploy this application into a live AWS environment. Locate TASK 13 (Line 101) which is responsible for gathering facts about AWS EC2 (VPC) instance and the deployed WordPress application that is running atop of it. TEMPLATE SOLUTION # TASK 13 # Gather facts about AWS EC2 (VPC) instance and deployed WordPress application. - name : Gather ec2 instance info for tag name wordpress # TASK 13 # Gather facts about AWS EC2 (VPC) instance and deployed WordPress application. - name : Gather ec2 instance info for tag name wordpress amazon.aws.ec2_instance_info : filters : tag:Name : wordpress instance-state-name : running register : ec2_facts Finally, you have arrived at the final step in the Playbook configuration: TASK 14 (Line 105), which is responsible for hosting the WordPress web app and making it accessible to users. TEMPLATE SOLUTION # TASK 14 # Host the WordPress web application and make accessible to user. - name : Debug ec2_facts public dns name # TASK 14 # Host the WordPress web application and make accessible to user. - name : Debug ec2_facts public dns name ansible.builtin.debug : msg : \"{ { ec2_facts.instances[0].public_dns_name } }/wordpress/readme.html\" Congratulations on making it this far! At this stage, your Playbook is ready for execution. However, there are still some preparation that you need to do before this Playbook can be used to automate deployment of the WordPress application into a live Amazon EC2 environment. If you wish to go ahead with the deployment ( RECOMMENDED ) on your personal AWS account, follow along with lab guide steps. Otherwise, you are welcome to conclude the hands-on component here and follow the Level 3 accreditation steps (depending on your role). LEVEL 3 ACCREDITATION IBMers should take the time now to prepare for and record their Stand & Deliver presentations for Level 3 accreditation. Be sure to follow the evaluation criteria that is outlined in this documentation. Business Partners should follow the learning plan links on IBM Training to complete a multiple-choice examination for Level 3 accreditation.","title":"Use Ansible Lightspeed to generate code with the TEMPLATE Playbook, then compare against the SOLUTION Playbook to evaluate the results."},{"location":"Lab/5-Advanced-Topics-EC2-WordPress/#_2","text":"","title":""},{"location":"Lab/5-Advanced-Topics-EC2-WordPress/#to-deploy-a-live-amazon-ec2-instance-and-wordpress-application-on-aws-follow-along-with-the-steps-below","text":"In order to execute the Ansible Playbook on your local machine, you will need to install Ansible locally. Red Hat provides extensive online documentation for how to go about installing Ansible. The authors of your lab guide recommend doing so by executing the following instructions in a Terminal window (macOS), or equivalent steps using PowerShell (Windows): brew install ansible MISSING HOMEBREW? If you do not have the Homebrew package manager (\"brew\") installed in a macOS environment, execute the following instruction inside a Terminal console: /bin/bash -c \"$(curl -fsSL https://raw.githubusercontent.com/Homebrew/install/HEAD/install.sh)\" Wait for the installation to conclude and then retry the instructions from Step 18. Follow the prompts until you receive confirmation that Ansible is installed and available locally. If you have not registered for an AWS account previously, you need to do so now before advancing. You will need to supply a personal credit card for billing expenses. If you have an existing Amazon account, your AWS account can be linked to that profile if you so choose. AWS Registration : https://aws.amazon.com/resources/create-account/ With a registered AWS account, you next need to navigate from the AWS dashboard into the Identity and Access Management (IAM) tool. You can search for this using the Search bar at the top of the screen and entering IAM . Once inside the IAM tool, look along the left-side of the interface and drill down into Users . Click the Create User orange button located in the top-right corner of the interface. Within the Create User panel, specify your user details and permissions. Set Username to a name of your choosing. Click Next to advance the configuration tool. Under Set Permissions > Permission Options , select the Add user to group tile. Click the Set permissions boundary - optional tile to expand additional permission options. Toggle the checkmark next to the Use a permissions boundary to control the maximum permissions option. Under Permissions Policies , search the table for the AdministratorAccess policy and enable that policy. You may receive warnings against doing so \u2014 ignore those for now. Continue following the prompts until the User has been created. Once the User has been created, your web browser will reopen the User panel of the IAM tool. Here you can see various details about the User, including their Security Credentials and any keys associated with the User. This section will be empty given that you have only just now created the User. Drill down into the Access Keys category and click the Create Access Key button located below the (empty) table. A secret access key will be created and the web browser will reload to show you details about that key. RECORD THIS INFORMATION to a notepad. Details about the secret access key can only be viewed or downloaded at the time the key is created (now). It cannot be recovered afterwards. However, if you lose your key details, all is not lost \u2014 you can always create a new secret access key at a later time. Record the Access Key , which will be used to replace the <PLACEHOLDER> value assigned to aws_access_key in Step 2 and Step 15 of this lab guide. Record the Secret Access Key , which will replace the <PLACEHOLDER> value assigned to aws_secret_key in Step 2 and Step 15 of this lab guide. Take note at this time as well about the Region in which your AWS account is located. You can easily look up this information by examining the URL in your web browser address bar, as shown below ( us-east-1 ). RECORD the name of the region, as this will replace the region value assigned to the Playbook. PLAYBOOK MODIFICATIONS REQUIRED Replace the <PLACEHOLDER> values for variables aws_access_key and aws_secret_key with the Access Key and Secret Access Key , respectively. Lines 13, 14, 96, and 97 of the TEMPLATE.yml Playbook Lines 13, 14, 179, and 180 of the SOLUTION.yml Playbook Replace the value for variable region with the region assigned to your unique AWS account. Lines 15 and 98 of the TEMPLATE.yml Playbook Lines 15 and 181 of the SOLUTION.yml Playbook Next, you'll need to create an SSH Key Pair with authorization to interact with (and ultimately deploy) Amazon EC2 instances. Return to the search bar at the top of the AWS interface and enter EC2 . Drill down into the Amazon EC2 service page from the results. From the left-hand navigation bar, drill down into the Network & Security > Key Pairs tab. Click the orange Create key pair button in the top-right of the page. A configuration tool will ask for additional information about the Key Pair: Name can be set to a value of your choosing Key pair type set to RSA Private key file format set to .pem When satisfied, click the orange Create key pair button. The web browser will redirect to a page where you can view details about the newly-created Key Pair for EC2. Download the .pem file to your local device, preferably to the same directory that your TEMPLATE.yml and SOLUTION.yml Playbooks are located within. PLAYBOOK MODIFICATIONS REQUIRED The value of ansible_ssh_private_key_file must be updated within your Playbooks to account for the full path to the .pem file on your local machine. If you save the Key Pair file to the same directory that your Ansible Playbooks are located within, you do not need to qualify the value with anything more than the name of the file ( bienko-key.pem ). If it is saved in a different directory, you will need to spell out the full path + file name. Update the value of ansible_ssh_private_key_file in the following locations: Line 58 of the TEMPLATE.yml Playbook Line 113 of the SOLUTION.yml Playbook It is necessary to adjust the permissions assigned to the Key Pair file (on your local machine) before attempting to connect via Ansible to AWS. Open a Terminal console on your local machine and navigate ( cd ) to the directory in which the Key Pair file is saved. Execute the following to adjust the permissions assigned to the .pem file: chmod 400 filename.pem","title":"To deploy a live Amazon EC2 instance and WordPress application on AWS, follow along with the steps below."},{"location":"Lab/5-Advanced-Topics-EC2-WordPress/#_3","text":"","title":""},{"location":"Lab/5-Advanced-Topics-EC2-WordPress/#executing-the-ansible-playbook","text":"At last, you are ready to execute the Playbook and use Ansible automation to deploy both an Amazon EC2 instance and a WordPress web application. With the Terminal console, navigate to the directory ( cd ) where both the Ansible Playbook and your KeyPair.pem file are located. You may use either the TEMPLATE.yml Playbook that you customized or the SOLUTION.yml Playbook for executing the Ansible automation tasks. Regardless of the Playbook being used, you must modify the Playbook with the necessary AWS security and account credentials information. When ready, execute the following instruction with the Terminal console: ansible-playbook TEMPLATE.yml Monitor the console's output as the Ansible Playbook iterates across each of the Tasks customized earlier. A fantastic feature of Ansible's automation is that if any of the Tasks should fail, the steps involved in that Task can be re-tried in subsequent runs; likewise, Tasks which executed successfully won't be repeated, but are validated and skipped instead. If you encounter errors during the litany of automation tasks, return to the Playbook and attempt to debug the issue. Re-issue the instruction in Step 34 to console to attempt the Ansible Playbook execution again. Continue iterating in this manner until all 14 Tasks have been successfully executed. After successfully deploying the Amazon EC2 environment and instantiating a WordPress application, the console will return a URL to the Terminal's output as part of Task 14's [debug] instruction. Copy the URL to clipboard and then paste it into your web browser to access the WordPress application. If your web browser loads the quick-start page for WordPress, you have successfully deployed the application and its supporting EC2 environment \u2014 entirely using Generative AI and Ansible automation. Well done!","title":"Executing the Ansible Playbook"},{"location":"Lab/5-Advanced-Topics-EC2-WordPress/#_4","text":"","title":""},{"location":"Lab/5-Advanced-Topics-EC2-WordPress/#cleaning-up-and-conclusion","text":"After you have recorded your Stand & Deliver presentations (IBM technical sellers only) and are ready to retire your environment, you will need to return to the AWS Dashboard to terminate the EC2 instance and hosted WordPress application. COSTS It is essential that you terminate and deprovision the EC2 instance at the conclusion of the hands on lab. Otherwise, your personal AWS account will continue to be billed for as long as the resources are provisioned. You can monitor your Amazon EC2 instance from the EC2 dashboard. At the top of the page, locate the Resources table and drill down into the Instances (running) tab. Details about your EC2 environment are summarized within the Instances table. Click the name of your EC2's Instance ID to expose additional details and management options. In the top-right corner of the interface, click the Instance state button and select Terminate instance from the drop-down menu. Confirm the deprovisioning request by clicking the orange Terminate button. All storage associated with the EC2 instance will automatically be deleted. Terminating an instance cannot be undone once underway. It is recommended that you delete all of the Security Groups (3 total) and Key Pairs (1 total) associated with the EC2 instance. To do so, return to the EC2 Dashboard and follow a similar procedure to Steps 38-41. Search for IAM in the AWS taskbar to return to the Identity Access Management panel. If you wish to further secure your AWS account, delete all unwanted users or consider reducing the user's privilege from AdministratorAccess to a more restrictive class. That concludes the hands-on components to this Level 3 course, but your learning and experimentation doesn't need to end here. Continue to experiment with generating Tasks for Ansible Playbooks. If you have worked extensively with Ansible previously, try recreating Tasks you've written previously from old Playbooks using generative AI \u2014 just be careful not to use confidential or sensitive information as part of those tests. See if you can spot the differences or improvements made from the AI-generated code recommendations. Feel free to reach out to the authors of this coursework if you have suggestions for Tasks or code generation techniques that you'd like to see included in future iterations of this hands-on training.","title":"Cleaning up and conclusion"}]}